{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fnxlNWWvnEqRNdZtMv4D6wbLMuXt7_fH","timestamp":1700597597689}],"gpuType":"T4","collapsed_sections":["hi8ncQuNamtA","TCHz2r4WjuNd","s-pvwooc5CMj","7Po-69Av5KDf","86FDpkq15Xux","9aylNMKzvokD","7bTAFdcO4668"],"toc_visible":true,"authorship_tag":"ABX9TyPGwwSJKC5whOTnA9qeWWIi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"66efe383ac1e45c186cebbae3438ef2a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c68c421a4fc4095baf942d988fbcb0f","IPY_MODEL_162b6e67ff9e4b3fb85e7c5ebf9eafbd","IPY_MODEL_a37297d3c26f4277836d72f008ce1be5"],"layout":"IPY_MODEL_49d92f730c0e460dbc3c0caa8f451022"}},"8c68c421a4fc4095baf942d988fbcb0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e502b4ea87241ee8d33f22769157a5d","placeholder":"​","style":"IPY_MODEL_485bda49bc6549249f08146fa6c9d404","value":"Downloading builder script: 100%"}},"162b6e67ff9e4b3fb85e7c5ebf9eafbd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fabcd510b09d47ffbaaf832257804edc","max":20771,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0088511d5b44e0a80a49523d5aeeadd","value":20771}},"a37297d3c26f4277836d72f008ce1be5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d2a5559703f4ed3a2f9db6acb00a5cc","placeholder":"​","style":"IPY_MODEL_8475eb9a572b4868a9c850d65e28ad26","value":" 20.8k/20.8k [00:00&lt;00:00, 1.16MB/s]"}},"49d92f730c0e460dbc3c0caa8f451022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e502b4ea87241ee8d33f22769157a5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"485bda49bc6549249f08146fa6c9d404":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fabcd510b09d47ffbaaf832257804edc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0088511d5b44e0a80a49523d5aeeadd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d2a5559703f4ed3a2f9db6acb00a5cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8475eb9a572b4868a9c850d65e28ad26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81da4ed8d29f4e829b0093b7c9b9c332":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_738b32bd9a074f93abff2b53aa23b89f","IPY_MODEL_e252a33e483b432ca6262d3facae23f5","IPY_MODEL_061bbaac7ba3477081827a7aa7b96430"],"layout":"IPY_MODEL_20317040dde1495eac136994463c0e4f"}},"738b32bd9a074f93abff2b53aa23b89f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26d4b8d102e848a589ff7d7768dbda3b","placeholder":"​","style":"IPY_MODEL_87d84d6d30e84877ae9e88a7186072d5","value":"Downloading metadata: 100%"}},"e252a33e483b432ca6262d3facae23f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67981ac1d3f9452aa77d55a71b0a89d7","max":31243,"min":0,"orientation":"horizontal","style":"IPY_MODEL_936ac709aa6a4b7bb0dd595b94b9395f","value":31243}},"061bbaac7ba3477081827a7aa7b96430":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ba45dc0262b47e7a8cb838c9b69e4d3","placeholder":"​","style":"IPY_MODEL_2eec881bfb2e44a7878e6b2cf0aff1ee","value":" 31.2k/31.2k [00:00&lt;00:00, 1.29MB/s]"}},"20317040dde1495eac136994463c0e4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26d4b8d102e848a589ff7d7768dbda3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87d84d6d30e84877ae9e88a7186072d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67981ac1d3f9452aa77d55a71b0a89d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"936ac709aa6a4b7bb0dd595b94b9395f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ba45dc0262b47e7a8cb838c9b69e4d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eec881bfb2e44a7878e6b2cf0aff1ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"209568d3f8f64ed2bf81b3383663a98e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5d9008a88d64dd09aa0a41462268846","IPY_MODEL_ac1c344c0e8e45169461981814dde015","IPY_MODEL_b3e60979db3d445981ba0d148c05e32b"],"layout":"IPY_MODEL_50191f1658884865bd61e93b4b7d2ea0"}},"b5d9008a88d64dd09aa0a41462268846":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c5581b4f8c342ce93521a7d5e0c0f17","placeholder":"​","style":"IPY_MODEL_de4b984f934549fc817cb6b071b7a7bd","value":"Downloading readme: 100%"}},"ac1c344c0e8e45169461981814dde015":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_139324db9b0f4a4faa93eb6871cfd185","max":13373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_286263ea917d4add9331bef7193bc0cb","value":13373}},"b3e60979db3d445981ba0d148c05e32b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19ddf16b84a548afa30667f569a6b7a2","placeholder":"​","style":"IPY_MODEL_7853df2aa0ca4c7a9a9e38acfd8dae80","value":" 13.4k/13.4k [00:00&lt;00:00, 432kB/s]"}},"50191f1658884865bd61e93b4b7d2ea0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c5581b4f8c342ce93521a7d5e0c0f17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de4b984f934549fc817cb6b071b7a7bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"139324db9b0f4a4faa93eb6871cfd185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"286263ea917d4add9331bef7193bc0cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19ddf16b84a548afa30667f569a6b7a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7853df2aa0ca4c7a9a9e38acfd8dae80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24d72f71a3774cf4b914588f51afdc25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1a11d9a380d42cd85bcb17235f07e95","IPY_MODEL_1cb97c0999604769ae17ae3c37f10f84","IPY_MODEL_ad8a6876604143ff8059c539008877fe"],"layout":"IPY_MODEL_d7371fa3fff54d4bb3889f9e1a8cc1a1"}},"c1a11d9a380d42cd85bcb17235f07e95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70366de666a94921b45e5bc9283d99f1","placeholder":"​","style":"IPY_MODEL_3ef04e16c2ad4fbead8673bdb9a8ddfa","value":"Downloading data: 100%"}},"1cb97c0999604769ae17ae3c37f10f84":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c14cf42bdfc5423e9d6036c8277b8860","max":432854,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24ac2ad8a31d4c07b410cba8d1e4910f","value":432854}},"ad8a6876604143ff8059c539008877fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a27f9767c1a4c80a898440cf6005532","placeholder":"​","style":"IPY_MODEL_16d5eaaad5304fe888b4a8602c57a5b4","value":" 433k/433k [00:00&lt;00:00, 1.24MB/s]"}},"d7371fa3fff54d4bb3889f9e1a8cc1a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70366de666a94921b45e5bc9283d99f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ef04e16c2ad4fbead8673bdb9a8ddfa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c14cf42bdfc5423e9d6036c8277b8860":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24ac2ad8a31d4c07b410cba8d1e4910f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a27f9767c1a4c80a898440cf6005532":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16d5eaaad5304fe888b4a8602c57a5b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25724c2074bd4f54a91ffabf900c083d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35f8032ec19c45f5ba24660cef194056","IPY_MODEL_37c6c0a04769481fa405c845487881d0","IPY_MODEL_a22b4f5ca29941269e107375d18b8d60"],"layout":"IPY_MODEL_64b505546b5b449eae3e69785a0a59b4"}},"35f8032ec19c45f5ba24660cef194056":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7ecd83e5e4e48d2836198e6bef42c0c","placeholder":"​","style":"IPY_MODEL_e8bcf5015e7048eea7c459ae0116df80","value":"Generating train split: 100%"}},"37c6c0a04769481fa405c845487881d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8037ba01b8c4ebc80240af61d3366ea","max":4823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bcd566c54264669a855d547789499c6","value":4823}},"a22b4f5ca29941269e107375d18b8d60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b66afd24cf142efa00226149ced8069","placeholder":"​","style":"IPY_MODEL_ea0dad0239bb47fbb4ede6b1e46567b1","value":" 4823/4823 [00:04&lt;00:00, 981.28 examples/s]"}},"64b505546b5b449eae3e69785a0a59b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7ecd83e5e4e48d2836198e6bef42c0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8bcf5015e7048eea7c459ae0116df80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8037ba01b8c4ebc80240af61d3366ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bcd566c54264669a855d547789499c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b66afd24cf142efa00226149ced8069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea0dad0239bb47fbb4ede6b1e46567b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"442c05047ea442d2b935cca0c963fbe5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6031de6a93e244b49839631e0f1230ed","IPY_MODEL_eb70554005564fff911dabc33070d6fa","IPY_MODEL_621dcf9fb7994c02b1bf2a89b1f879a9"],"layout":"IPY_MODEL_bf040b868ae046a5b96aea1f36372eec"}},"6031de6a93e244b49839631e0f1230ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43e1402bdaa748cea27caacb2ce2f1ec","placeholder":"​","style":"IPY_MODEL_f33a87dd3e844545ba36bd6aea2379c8","value":"Generating validation split: 100%"}},"eb70554005564fff911dabc33070d6fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d493feb1c3347999cbf3a3a02f34ff7","max":744,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc4412a2cc544586b964e7bb00a7a9a5","value":744}},"621dcf9fb7994c02b1bf2a89b1f879a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_750a331c4cba444788f7ce4d198d9b8d","placeholder":"​","style":"IPY_MODEL_f51ffcfc5b0141bf9fb3bfd8a61021b0","value":" 744/744 [00:00&lt;00:00, 882.26 examples/s]"}},"bf040b868ae046a5b96aea1f36372eec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43e1402bdaa748cea27caacb2ce2f1ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f33a87dd3e844545ba36bd6aea2379c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d493feb1c3347999cbf3a3a02f34ff7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc4412a2cc544586b964e7bb00a7a9a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"750a331c4cba444788f7ce4d198d9b8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f51ffcfc5b0141bf9fb3bfd8a61021b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1bd4e1a640b479f8c74d7d1064af994":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80904e654ce8475e921f8fdf5b2e0f8c","IPY_MODEL_2c2cd04028b84d6887a43a3960c89e33","IPY_MODEL_12130fb9d7d74c4f81f83d6e893a43c0"],"layout":"IPY_MODEL_3ee924ad660f4563b13d94ce19b826a9"}},"80904e654ce8475e921f8fdf5b2e0f8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1e62b28e72d4c218f04de3eea81786c","placeholder":"​","style":"IPY_MODEL_807df876ac7f4c8a8106c93d41bccbc2","value":"Generating test split: 100%"}},"2c2cd04028b84d6887a43a3960c89e33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fe1e236469643da97bb62b2de9d31d4","max":1854,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01d6d4f221df47b3b32d7e8e7ea03405","value":1854}},"12130fb9d7d74c4f81f83d6e893a43c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f37ab0204d9408d9e8bee43fafaeb06","placeholder":"​","style":"IPY_MODEL_d3186f9a052e47a6b794513fd834a51e","value":" 1854/1854 [00:01&lt;00:00, 2224.15 examples/s]"}},"3ee924ad660f4563b13d94ce19b826a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e62b28e72d4c218f04de3eea81786c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"807df876ac7f4c8a8106c93d41bccbc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fe1e236469643da97bb62b2de9d31d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01d6d4f221df47b3b32d7e8e7ea03405":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f37ab0204d9408d9e8bee43fafaeb06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3186f9a052e47a6b794513fd834a51e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["### Importing Libraries"],"metadata":{"id":"0kGj-n_YVnDP"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import nltk\n","nltk.download('wordnet')\n","import re\n","# import contractions\n","import string\n","from bs4 import BeautifulSoup\n","# import requests\n","# from collections import Counter\n","# from num2words import num2words\n","from wordcloud import WordCloud, ImageColorGenerator\n","from nltk.tokenize import word_tokenize\n","from tqdm import tqdm\n","tqdm.pandas()\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","from plotly import graph_objs as go\n","import plotly.express as px\n","import plotly.figure_factory as ff\n","# import spacy\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","import nltk\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from nltk.corpus import stopwords\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# pd.set_option('max_colwidth', 99999)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGYHc_VPq-JQ","executionInfo":{"status":"ok","timestamp":1700597667842,"user_tz":480,"elapsed":38796,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"49dc0e3e-237a-4c40-fbd5-631c72174efb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WxQad0P7UQUq","executionInfo":{"status":"ok","timestamp":1700597676483,"user_tz":480,"elapsed":8649,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"3d3bdfad-0846-4c4b-847c-f06a9a538d5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting pyarrow-hotfix (from datasets)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n","Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n","Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n"]}]},{"cell_type":"markdown","source":["### Dataset Retrieval"],"metadata":{"id":"BcqIxHmiaWt-"}},{"cell_type":"code","source":["from datasets import load_dataset\n","dataset = load_dataset(\"lince\",'lid_hineng', download_mode=\"force_redownload\")\n","print(f\"Train dataset size: {len(dataset['train'])}\")\n","print(f\"Test dataset size: {len(dataset['test'])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277,"referenced_widgets":["66efe383ac1e45c186cebbae3438ef2a","8c68c421a4fc4095baf942d988fbcb0f","162b6e67ff9e4b3fb85e7c5ebf9eafbd","a37297d3c26f4277836d72f008ce1be5","49d92f730c0e460dbc3c0caa8f451022","9e502b4ea87241ee8d33f22769157a5d","485bda49bc6549249f08146fa6c9d404","fabcd510b09d47ffbaaf832257804edc","c0088511d5b44e0a80a49523d5aeeadd","5d2a5559703f4ed3a2f9db6acb00a5cc","8475eb9a572b4868a9c850d65e28ad26","81da4ed8d29f4e829b0093b7c9b9c332","738b32bd9a074f93abff2b53aa23b89f","e252a33e483b432ca6262d3facae23f5","061bbaac7ba3477081827a7aa7b96430","20317040dde1495eac136994463c0e4f","26d4b8d102e848a589ff7d7768dbda3b","87d84d6d30e84877ae9e88a7186072d5","67981ac1d3f9452aa77d55a71b0a89d7","936ac709aa6a4b7bb0dd595b94b9395f","1ba45dc0262b47e7a8cb838c9b69e4d3","2eec881bfb2e44a7878e6b2cf0aff1ee","209568d3f8f64ed2bf81b3383663a98e","b5d9008a88d64dd09aa0a41462268846","ac1c344c0e8e45169461981814dde015","b3e60979db3d445981ba0d148c05e32b","50191f1658884865bd61e93b4b7d2ea0","0c5581b4f8c342ce93521a7d5e0c0f17","de4b984f934549fc817cb6b071b7a7bd","139324db9b0f4a4faa93eb6871cfd185","286263ea917d4add9331bef7193bc0cb","19ddf16b84a548afa30667f569a6b7a2","7853df2aa0ca4c7a9a9e38acfd8dae80","24d72f71a3774cf4b914588f51afdc25","c1a11d9a380d42cd85bcb17235f07e95","1cb97c0999604769ae17ae3c37f10f84","ad8a6876604143ff8059c539008877fe","d7371fa3fff54d4bb3889f9e1a8cc1a1","70366de666a94921b45e5bc9283d99f1","3ef04e16c2ad4fbead8673bdb9a8ddfa","c14cf42bdfc5423e9d6036c8277b8860","24ac2ad8a31d4c07b410cba8d1e4910f","0a27f9767c1a4c80a898440cf6005532","16d5eaaad5304fe888b4a8602c57a5b4","25724c2074bd4f54a91ffabf900c083d","35f8032ec19c45f5ba24660cef194056","37c6c0a04769481fa405c845487881d0","a22b4f5ca29941269e107375d18b8d60","64b505546b5b449eae3e69785a0a59b4","f7ecd83e5e4e48d2836198e6bef42c0c","e8bcf5015e7048eea7c459ae0116df80","d8037ba01b8c4ebc80240af61d3366ea","8bcd566c54264669a855d547789499c6","5b66afd24cf142efa00226149ced8069","ea0dad0239bb47fbb4ede6b1e46567b1","442c05047ea442d2b935cca0c963fbe5","6031de6a93e244b49839631e0f1230ed","eb70554005564fff911dabc33070d6fa","621dcf9fb7994c02b1bf2a89b1f879a9","bf040b868ae046a5b96aea1f36372eec","43e1402bdaa748cea27caacb2ce2f1ec","f33a87dd3e844545ba36bd6aea2379c8","5d493feb1c3347999cbf3a3a02f34ff7","dc4412a2cc544586b964e7bb00a7a9a5","750a331c4cba444788f7ce4d198d9b8d","f51ffcfc5b0141bf9fb3bfd8a61021b0","c1bd4e1a640b479f8c74d7d1064af994","80904e654ce8475e921f8fdf5b2e0f8c","2c2cd04028b84d6887a43a3960c89e33","12130fb9d7d74c4f81f83d6e893a43c0","3ee924ad660f4563b13d94ce19b826a9","e1e62b28e72d4c218f04de3eea81786c","807df876ac7f4c8a8106c93d41bccbc2","4fe1e236469643da97bb62b2de9d31d4","01d6d4f221df47b3b32d7e8e7ea03405","1f37ab0204d9408d9e8bee43fafaeb06","d3186f9a052e47a6b794513fd834a51e"]},"id":"6lw8L26KTRyn","outputId":"b321c608-064a-457c-9fc7-8d8c66d9a9a5","executionInfo":{"status":"ok","timestamp":1700597687577,"user_tz":480,"elapsed":11111,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66efe383ac1e45c186cebbae3438ef2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading metadata:   0%|          | 0.00/31.2k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81da4ed8d29f4e829b0093b7c9b9c332"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/13.4k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"209568d3f8f64ed2bf81b3383663a98e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/433k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24d72f71a3774cf4b914588f51afdc25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/4823 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25724c2074bd4f54a91ffabf900c083d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/744 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"442c05047ea442d2b935cca0c963fbe5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/1854 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1bd4e1a640b479f8c74d7d1064af994"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train dataset size: 4823\n","Test dataset size: 1854\n"]}]},{"cell_type":"code","source":["dataset['train']"],"metadata":{"id":"mj3lilcOUjtM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700597687755,"user_tz":480,"elapsed":194,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"f99dbdfa-8b31-45c9-bd76-8e2b8fc17c28"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['idx', 'words', 'lid'],\n","    num_rows: 4823\n","})"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["### Prepare data"],"metadata":{"id":"hi8ncQuNamtA"}},{"cell_type":"code","source":["trid = pd.Series(dataset['train']['idx'])\n","trwo = pd.Series(dataset['train']['words'])\n","trli = pd.Series(dataset['train']['lid'])\n","train = pd.DataFrame({'id':trid, 'words':trwo, 'lid':trli})\n","\n","vaid = pd.Series(dataset['validation']['idx'])\n","vawo = pd.Series(dataset['validation']['words'])\n","vali = pd.Series(dataset['validation']['lid'])\n","valid = pd.DataFrame({'id':vaid, 'words':vawo, 'lid':vali})\n","\n","teid = pd.Series(dataset['test']['idx'])\n","tewo = pd.Series(dataset['test']['words'])\n","test = pd.DataFrame({'id':teid, 'words':tewo})"],"metadata":{"id":"F06WwI1pX8iw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"wxirJ4vZVtRh","executionInfo":{"status":"ok","timestamp":1700597688385,"user_tz":480,"elapsed":27,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"c12981c1-756c-4378-866f-26639df2704e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id                                              words  \\\n","0        0                             [Good, vibe, tribe, .]   \n","1        1  [beware, #pmjohnkey, .., ., maintain, distance...   \n","2        2                       [Angry, young, men, sir, ji]   \n","3        3  [Girlfriend, 's, Guide, To, Divorce, is, the, ...   \n","4        4  [Ajay, thakur, ,, woww, this, is, why, kabaddi...   \n","...    ...                                                ...   \n","4818  4818                                    [Hats, Off, !!]   \n","4819  4819  [par, toda, dhyan, se, sahab, 62, me, bhi, en,...   \n","4820  4820  [Kya, saalo, kb, se, daily, dekhta, ho, ki, sa...   \n","4821  4821                  [hi, amir, my, name, nadim, khan]   \n","4822  4822  [@yashchandy, I, finished, that, sentence, as,...   \n","\n","                                                    lid  \n","0                          [lang1, lang1, lang1, other]  \n","1     [lang1, ne, other, other, lang1, lang1, lang1,...  \n","2                   [lang1, lang1, lang1, lang1, lang2]  \n","3     [lang1, lang1, lang1, lang1, lang1, lang1, lan...  \n","4     [ne, ne, other, lang1, lang1, lang1, lang1, la...  \n","...                                                 ...  \n","4818                              [lang1, lang1, other]  \n","4819  [lang1, lang2, lang2, lang2, lang2, other, lan...  \n","4820  [lang2, lang2, lang2, lang2, lang1, lang2, lan...  \n","4821                  [lang2, ne, lang1, lang1, ne, ne]  \n","4822  [other, lang1, lang1, lang1, lang1, lang1, oth...  \n","\n","[4823 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-b2e725ee-2872-477d-8210-37ea88341c16\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>words</th>\n","      <th>lid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[Good, vibe, tribe, .]</td>\n","      <td>[lang1, lang1, lang1, other]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>[beware, #pmjohnkey, .., ., maintain, distance...</td>\n","      <td>[lang1, ne, other, other, lang1, lang1, lang1,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>[Angry, young, men, sir, ji]</td>\n","      <td>[lang1, lang1, lang1, lang1, lang2]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>[Girlfriend, 's, Guide, To, Divorce, is, the, ...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>[Ajay, thakur, ,, woww, this, is, why, kabaddi...</td>\n","      <td>[ne, ne, other, lang1, lang1, lang1, lang1, la...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4818</th>\n","      <td>4818</td>\n","      <td>[Hats, Off, !!]</td>\n","      <td>[lang1, lang1, other]</td>\n","    </tr>\n","    <tr>\n","      <th>4819</th>\n","      <td>4819</td>\n","      <td>[par, toda, dhyan, se, sahab, 62, me, bhi, en,...</td>\n","      <td>[lang1, lang2, lang2, lang2, lang2, other, lan...</td>\n","    </tr>\n","    <tr>\n","      <th>4820</th>\n","      <td>4820</td>\n","      <td>[Kya, saalo, kb, se, daily, dekhta, ho, ki, sa...</td>\n","      <td>[lang2, lang2, lang2, lang2, lang1, lang2, lan...</td>\n","    </tr>\n","    <tr>\n","      <th>4821</th>\n","      <td>4821</td>\n","      <td>[hi, amir, my, name, nadim, khan]</td>\n","      <td>[lang2, ne, lang1, lang1, ne, ne]</td>\n","    </tr>\n","    <tr>\n","      <th>4822</th>\n","      <td>4822</td>\n","      <td>[@yashchandy, I, finished, that, sentence, as,...</td>\n","      <td>[other, lang1, lang1, lang1, lang1, lang1, oth...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4823 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2e725ee-2872-477d-8210-37ea88341c16')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b2e725ee-2872-477d-8210-37ea88341c16 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b2e725ee-2872-477d-8210-37ea88341c16');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-286d5b3f-1768-406c-b4df-a0ee629227b7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-286d5b3f-1768-406c-b4df-a0ee629227b7')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-286d5b3f-1768-406c-b4df-a0ee629227b7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["copytrain = train.copy()"],"metadata":{"id":"Vt3-sS0QZxcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain = copytrain[['id', 'words', 'lid']]"],"metadata":{"id":"RGXd9GYYKQQ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['old_words'] = copytrain['words']\n","copytrain['old_lid'] = copytrain['lid']"],"metadata":{"id":"zHayK3LsjQgt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_video_tags(tokens):\n","    '''\n","    remove_video_tags:\n","    Removes video tags from a list of words.\n","    Args:\n","      tokens (list) : List of words with video tags\n","    Returns:\n","      filtered_tokens (list) : List of words without video tags\n","    '''\n","    clean = re.compile('[[.*?]]')\n","    filtered_tokens = [re.sub(clean, '', token) for token in tokens]\n","    return filtered_tokens\n","\n","def remove_multiple_letters(tokens):\n","    '''\n","    remove_multiple_letters:\n","    Replace words with more than 2 consecutive letters with 2 consecutive letters in a list of words.\n","    Args:\n","      tokens (list) : List of words to process\n","    Returns:\n","      processed_tokens (list) : List of words with replacements\n","    '''\n","    processed_tokens = [re.sub(r'(.)\\1{2,}', r'\\1\\1', token) for token in tokens]\n","    return processed_tokens\n","\n","def joinstr(tokens):\n","    '''\n","    joinstr:\n","    Joins a list of words with periods.\n","    Args:\n","      tokens (list) : List of words\n","    Returns:\n","      joined_str (str) : String as list joined with periods\n","    '''\n","    joined_str = '.'.join(tokens)\n","    return joined_str\n","\n","def remove_html_tags(tokens):\n","    '''\n","    remove_html_tags:\n","    Removes HTML tags from a list of words.\n","    Args:\n","      tokens (list) : List of words with HTML tags\n","    Returns:\n","      filtered_tokens (list) : List of words without HTML tags\n","    '''\n","    clean = re.compile('<.*?>')\n","    filtered_tokens = [re.sub(clean, '', token) for token in tokens]\n","    return filtered_tokens\n","\n","def remove_url(tokens):\n","    '''\n","    remove_url:\n","    Removes words containing 'http' or 'www' from a list of words.\n","    Args:\n","      tokens (list) : List of words\n","    Returns:\n","      filtered_tokens (list) : List of words with 'http' or 'www' removed\n","    '''\n","    filtered_tokens = [token if 'http' not in token and 'www' not in token else '' for token in tokens]\n","    return filtered_tokens\n","\n","def remove_attherate(tokens):\n","    '''\n","    remove_url:\n","    Removes words containing 'http' or 'www' from a list of words.\n","    Args:\n","      tokens (list) : List of words\n","    Returns:\n","      filtered_tokens (list) : List of words with 'http' or 'www' removed\n","    '''\n","    filtered_tokens = [token if '@' not in token else '' for token in tokens]\n","    return filtered_tokens"],"metadata":{"id":"b93JZ5OxeDCX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_removed_indices(original_list, modified_list):\n","    # Find indices of blank strings in the modified list\n","    removed_indices = [i for i, item in enumerate(modified_list) if item == \"\"]\n","    return removed_indices\n","\n","def del_list_indexes(l, id_to_del):\n","    somelist = [i for j, i in enumerate(l) if j not in id_to_del]\n","    return somelist\n","\n","def remove_blank_strings(tokens):\n","    tokens = [x for x in tokens if x]\n","    return tokens\n","\n","def lower_case(tokens):\n","    tokens = [x.lower() for x in tokens]\n","    return tokens\n","\n","def blank_consecutive_duplicates(input_list, blank_value=''):\n","    if not input_list:\n","        return input_list  # Return an empty list if the input list is empty\n","    # Initialize a new list with the first element from the input list\n","    result_list = [input_list[0]]\n","    # Iterate through the input list, starting from the second element\n","    for i in range(1, len(input_list)):\n","        if input_list[i] == input_list[i - 1]:\n","            result_list.append(blank_value)\n","        else:\n","            result_list.append(input_list[i])\n","    return result_list\n","\n","def replace_words_and_tags(row):\n","    words = row['words']\n","    lid = row['lid']\n","\n","    for i in range(len(lid)):\n","        if lid[i] in drop_lids:\n","            words[i] = ''  # Replace the word with a blank string\n","            lid[i] = ''   # Replace the tag with a blank string\n","\n","    return pd.Series({'words': words, 'lid': lid})\n","\n","def update_words_lid(copytrain):\n","  for i in range(len(copytrain['words'])):\n","    m = find_removed_indices(copytrain['words'][i], copytrain['n_words'][i])\n","    copytrain['lid'][i] = del_list_indexes(copytrain['lid'][i], m)\n","  copytrain['n_words'] = copytrain['n_words'].apply(lambda x: remove_blank_strings(x))\n","  copytrain['words'] = copytrain['n_words']"],"metadata":{"id":"tBahqcPXhWBn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['n_words'] = copytrain['words'].apply(lambda x: remove_video_tags(x))\n","update_words_lid(copytrain)"],"metadata":{"id":"k9jAuIHzjfUP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['n_words'] = copytrain['words'].apply(lambda x: remove_html_tags(x))\n","update_words_lid(copytrain)"],"metadata":{"id":"48ntVxmriVZe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['n_words'] = copytrain['words'].apply(lambda x: remove_url(x))\n","update_words_lid(copytrain)"],"metadata":{"id":"64vGfgWYkpOl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['n_words'] = copytrain['words'].apply(lambda x: remove_attherate(x))\n","update_words_lid(copytrain)"],"metadata":{"id":"N6dunaxfFDVh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['n_words'] = copytrain['words'].apply(lambda tokens: [re.sub(r'[^A-Za-z ]+', '', word) for word in tokens])\n","update_words_lid(copytrain)"],"metadata":{"id":"ekMDaQ0dhWJE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['n_words'] = copytrain['words'].apply(lambda x: remove_multiple_letters(x))\n","update_words_lid(copytrain)"],"metadata":{"id":"AU_lAUi5ktlh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['n_words'] = copytrain['words'].apply(lambda x: lower_case(x))\n","update_words_lid(copytrain)"],"metadata":{"id":"Jnz3-ucutd3C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['n_words'] = copytrain['words'].apply(lambda x: blank_consecutive_duplicates(x))\n","update_words_lid(copytrain)"],"metadata":{"id":"117JMA4WrvIM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lid = list(copytrain['lid'])\n","wordlist = list(copytrain['words'])\n","flat_lid = [item for sublist in lid for item in sublist]\n","flat_wordlist = [item for sublist in wordlist for item in sublist]\n","key = list(set(flat_lid))\n","pd.Series(flat_wordlist)\n","pd.Series(flat_lid)\n","flat = pd.DataFrame({'words':flat_wordlist, 'lid':flat_lid})\n","for i in key:\n","  print(str(i) + ': ' +str(flat['words'][flat['lid']==i].value_counts().sum()))\n","  print(flat['words'][flat['lid']==i].value_counts()[:20])\n","  print('-------')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hh5_eQFr6Wup","executionInfo":{"status":"ok","timestamp":1700597716900,"user_tz":480,"elapsed":946,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"2fa56a33-5dee-4b88-8c4f-605702b85442"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["lang1: 54785\n","the     1463\n","to      1263\n","you     1163\n","i       1134\n","and     1046\n","of       965\n","in       937\n","is       881\n","a        845\n","sir      668\n","u        658\n","for      651\n","are      484\n","it       431\n","we       413\n","this     404\n","love     366\n","best     359\n","all      357\n","my       355\n","Name: words, dtype: int64\n","-------\n","mixed: 39\n","sirji                        4\n","loansepehlelog               2\n","chootiyas                    2\n","lathicharge                  1\n","worlcupdobara                1\n","randis                       1\n","silentjihad                  1\n","bhogies                      1\n","rakhis                       1\n","betis                        1\n","pranams                      1\n","dedhlitre                    1\n","stwo                         1\n","muggus                       1\n","songse                       1\n","happyjanmashtamidhonibhai    1\n","pmji                         1\n","bhaiyas                      1\n","jawans                       1\n","konas                        1\n","Name: words, dtype: int64\n","-------\n","ne: 6288\n","india       475\n","virat       254\n","modi        241\n","salman      140\n","dhoni       125\n","kohli       120\n","khan        118\n","pakistan     98\n","aamir        90\n","russia       72\n","diwali       54\n","priyanka     54\n","indian       49\n","ms           42\n","modiji       42\n","narendra     34\n","dangal       33\n","delhi        31\n","sultan       31\n","amir         30\n","Name: words, dtype: int64\n","-------\n","ambiguous: 8\n","by       2\n","r        1\n","las      1\n","beger    1\n","trsut    1\n","me       1\n","to       1\n","Name: words, dtype: int64\n","-------\n","unk: 10\n","y         1\n","gavi      1\n","kamboj    1\n","prash     1\n","gant      1\n","saa       1\n","lb        1\n","m         1\n","been      1\n","cajun     1\n","Name: words, dtype: int64\n","-------\n","lang2: 19076\n","hai     564\n","ki      379\n","ji      310\n","ko      302\n","bhai    290\n","ke      268\n","ho      267\n","ka      254\n","h       247\n","to      244\n","me      230\n","se      220\n","bhi     218\n","aap     204\n","hi      194\n","nahi    167\n","aur     164\n","k       150\n","koi     128\n","kya     125\n","Name: words, dtype: int64\n","-------\n","other: 392\n","p         62\n","d         36\n","oh        24\n","th        18\n","ha        16\n","nd        14\n","s         13\n","h         11\n","haha      10\n","am        10\n","hahaha     9\n","m          8\n","pm         7\n","a          5\n","uff        5\n","yup        4\n","xd         4\n","v          4\n","hmm        4\n","cr         4\n","Name: words, dtype: int64\n","-------\n","fw: 405\n","halamadrid    6\n","na            5\n","thalaivar     5\n","dar           5\n","ki            4\n","hoy           4\n","tere          4\n","thala         3\n","to            3\n","mama          3\n","karo          3\n","pan           3\n","ta            3\n","ho            3\n","bari          3\n","da            3\n","lo            2\n","nu            2\n","are           2\n","korbo         2\n","Name: words, dtype: int64\n","-------\n"]}]},{"cell_type":"code","source":["drop_lids = ['ambiguous','unk', 'mixed', 'other']"],"metadata":{"id":"a3Sw1fEW8i98"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain[['n_words','lid']] = copytrain.apply(replace_words_and_tags, axis=1)"],"metadata":{"id":"2lX7gNev9RCQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["update_words_lid(copytrain)"],"metadata":{"id":"ywUVt3SEBeGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['words'] = copytrain['n_words']"],"metadata":{"id":"2paV3Gs-B7MT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Merging fw with lang2 and ne with lang1"],"metadata":{"id":"XPrOAETnGLaj"}},{"cell_type":"code","source":["for i in range(len(copytrain['lid'])):\n","  for j in range(len(copytrain['lid'][i])):\n","    if copytrain['lid'][i][j] == 'fw':\n","      copytrain['lid'][i][j] = 'lang2'\n","    if copytrain['lid'][i][j] == 'ne':\n","      copytrain['lid'][i][j] = 'lang1'"],"metadata":{"id":"9uRoFpghGXSC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lid = list(copytrain['lid'])\n","wordlist = list(copytrain['words'])\n","flat_lid = [item for sublist in lid for item in sublist]\n","flat_wordlist = [item for sublist in wordlist for item in sublist]\n","key = list(set(flat_lid))\n","pd.Series(flat_wordlist)\n","pd.Series(flat_lid)\n","flat = pd.DataFrame({'words':flat_wordlist, 'lid':flat_lid})\n","for i in key:\n","  print(str(i) + ': ' +str(flat['words'][flat['lid']==i].value_counts().sum()))\n","  print(flat['words'][flat['lid']==i].value_counts()[:20])\n","  print('-------')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_W6o05NGtOx","executionInfo":{"status":"ok","timestamp":1700597725200,"user_tz":480,"elapsed":5,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"ec54981f-4012-47e7-c942-279f4e3e5b09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["lang1: 61073\n","the      1468\n","to       1263\n","you      1163\n","i        1135\n","and      1048\n","of        970\n","in        937\n","is        881\n","a         846\n","sir       668\n","u         659\n","for       651\n","are       484\n","india     476\n","it        431\n","we        413\n","this      404\n","love      368\n","best      359\n","all       357\n","Name: words, dtype: int64\n","-------\n","lang2: 19481\n","hai     564\n","ki      383\n","ji      310\n","ko      302\n","bhai    290\n","ho      270\n","ke      268\n","ka      255\n","to      247\n","h       247\n","me      230\n","se      221\n","bhi     218\n","aap     204\n","hi      196\n","nahi    167\n","aur     164\n","k       152\n","koi     130\n","kya     125\n","Name: words, dtype: int64\n","-------\n"]}]},{"cell_type":"code","source":["copytrain['final_lid_str'] = ''\n","copytrain['final_lid'] = ''"],"metadata":{"id":"O3lN3r68HLI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def assign_language(row):\n","    if 'lang1' in row['lid'] and 'lang2' in row['lid']:\n","        return 'bi'\n","    elif 'lang1' in row['lid']:\n","        return 'eng'\n","    elif 'lang2' in row['lid']:\n","        return 'hin'\n","    else:\n","        return None  # Or any other default value you prefer"],"metadata":{"id":"om_yewk-NL3L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['final_lid'] = copytrain.apply(assign_language, axis=1)"],"metadata":{"id":"MHdyjgtFNWgu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain[['words','lid','final_lid']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"LqcNuCC8IYfh","executionInfo":{"status":"ok","timestamp":1700597725383,"user_tz":480,"elapsed":20,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"024ea6af-80c0-4717-f07c-cbc94b1ad978"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  words  \\\n","0                                   [good, vibe, tribe]   \n","1     [beware, pmjohnkey, maintain, distance, from, ...   \n","2                          [angry, young, men, sir, ji]   \n","3     [girlfriend, s, guide, to, divorce, is, the, b...   \n","4     [ajay, thakur, woww, this, is, why, kabaddi, i...   \n","...                                                 ...   \n","4818                                        [hats, off]   \n","4819  [par, toda, dhyan, se, sahab, me, bhi, en, log...   \n","4820  [kya, saalo, kb, se, daily, dekhta, ho, ki, sa...   \n","4821                  [hi, amir, my, name, nadim, khan]   \n","4822  [i, finished, that, sentence, as, sharma, aunt...   \n","\n","                                                    lid final_lid  \n","0                                 [lang1, lang1, lang1]       eng  \n","1     [lang1, lang1, lang1, lang1, lang1, lang1, lan...       eng  \n","2                   [lang1, lang1, lang1, lang1, lang2]        bi  \n","3     [lang1, lang1, lang1, lang1, lang1, lang1, lan...       eng  \n","4     [lang1, lang1, lang1, lang1, lang1, lang1, lan...        bi  \n","...                                                 ...       ...  \n","4818                                     [lang1, lang1]       eng  \n","4819  [lang1, lang2, lang2, lang2, lang2, lang2, lan...        bi  \n","4820  [lang2, lang2, lang2, lang2, lang1, lang2, lan...        bi  \n","4821         [lang2, lang1, lang1, lang1, lang1, lang1]        bi  \n","4822  [lang1, lang1, lang1, lang1, lang1, lang1, lan...        bi  \n","\n","[4823 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-8e2b3f5c-4992-451a-8a89-db3df2f2aa37\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>lid</th>\n","      <th>final_lid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[good, vibe, tribe]</td>\n","      <td>[lang1, lang1, lang1]</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[beware, pmjohnkey, maintain, distance, from, ...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[angry, young, men, sir, ji]</td>\n","      <td>[lang1, lang1, lang1, lang1, lang2]</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[girlfriend, s, guide, to, divorce, is, the, b...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[ajay, thakur, woww, this, is, why, kabaddi, i...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4818</th>\n","      <td>[hats, off]</td>\n","      <td>[lang1, lang1]</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>4819</th>\n","      <td>[par, toda, dhyan, se, sahab, me, bhi, en, log...</td>\n","      <td>[lang1, lang2, lang2, lang2, lang2, lang2, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>4820</th>\n","      <td>[kya, saalo, kb, se, daily, dekhta, ho, ki, sa...</td>\n","      <td>[lang2, lang2, lang2, lang2, lang1, lang2, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>4821</th>\n","      <td>[hi, amir, my, name, nadim, khan]</td>\n","      <td>[lang2, lang1, lang1, lang1, lang1, lang1]</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>4822</th>\n","      <td>[i, finished, that, sentence, as, sharma, aunt...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4823 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e2b3f5c-4992-451a-8a89-db3df2f2aa37')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8e2b3f5c-4992-451a-8a89-db3df2f2aa37 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8e2b3f5c-4992-451a-8a89-db3df2f2aa37');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4d3e16e3-e8a7-42f6-b1d2-5776f8ddb338\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d3e16e3-e8a7-42f6-b1d2-5776f8ddb338')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4d3e16e3-e8a7-42f6-b1d2-5776f8ddb338 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["def prepdata(train):\n","  copytrain = train.copy()\n","  copytrain = copytrain[['id', 'words', 'lid']]\n","  copytrain['old_words'] = copytrain['words']\n","  copytrain['old_lid'] = copytrain['lid']\n","  copytrain['n_words'] = copytrain['words'].apply(lambda x: remove_video_tags(x))\n","  update_words_lid(copytrain)\n","  copytrain['n_words'] = copytrain['words'].apply(lambda x: remove_html_tags(x))\n","  update_words_lid(copytrain)\n","  copytrain['n_words'] = copytrain['words'].apply(lambda x: remove_url(x))\n","  update_words_lid(copytrain)\n","  copytrain['n_words'] = copytrain['words'].apply(lambda x: remove_attherate(x))\n","  update_words_lid(copytrain)\n","  copytrain['n_words'] = copytrain['words'].apply(lambda tokens: [re.sub(r'[^A-Za-z ]+', '', word) for word in tokens])\n","  update_words_lid(copytrain)\n","  copytrain['n_words'] = copytrain['words'].apply(lambda x: remove_multiple_letters(x))\n","  update_words_lid(copytrain)\n","  copytrain['n_words'] = copytrain['words'].apply(lambda x: lower_case(x))\n","  update_words_lid(copytrain)\n","  copytrain['n_words'] = copytrain['words'].apply(lambda x: blank_consecutive_duplicates(x))\n","  update_words_lid(copytrain)\n","  drop_lids = ['ambiguous','unk', 'mixed', 'other']\n","  copytrain[['n_words','lid']] = copytrain.apply(replace_words_and_tags, axis=1)\n","  update_words_lid(copytrain)\n","  copytrain['words'] = copytrain['n_words']\n","  for i in range(len(copytrain['lid'])):\n","    for j in range(len(copytrain['lid'][i])):\n","      if copytrain['lid'][i][j] == 'fw':\n","        copytrain['lid'][i][j] = 'lang2'\n","      if copytrain['lid'][i][j] == 'ne':\n","        copytrain['lid'][i][j] = 'lang1'\n","  copytrain['final_lid'] = ''\n","  copytrain['final_lid'] = copytrain.apply(assign_language, axis=1)\n","  return copytrain[['words','lid','final_lid']]"],"metadata":{"id":"46UQTOVR79gH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["validation_data = prepdata(valid)"],"metadata":{"id":"5ne1Ecf783Zw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copytrain['final_lid'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vpy94MNQL8uH","executionInfo":{"status":"ok","timestamp":1700597728512,"user_tz":480,"elapsed":33,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"f187035a-c2a0-4d57-eb99-379238d7672f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["eng    2478\n","bi     2236\n","hin     103\n","Name: final_lid, dtype: int64"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["dx = copytrain[['words','lid','final_lid']]"],"metadata":{"id":"nU5zkt-q1csz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"A7rih6tkX_yn","executionInfo":{"status":"ok","timestamp":1700597728514,"user_tz":480,"elapsed":31,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"d2af89b1-d7f4-48f3-9267-c8af264a9cfd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  words  \\\n","0                                   [good, vibe, tribe]   \n","1     [beware, pmjohnkey, maintain, distance, from, ...   \n","2                          [angry, young, men, sir, ji]   \n","3     [girlfriend, s, guide, to, divorce, is, the, b...   \n","4     [ajay, thakur, woww, this, is, why, kabaddi, i...   \n","...                                                 ...   \n","4818                                        [hats, off]   \n","4819  [par, toda, dhyan, se, sahab, me, bhi, en, log...   \n","4820  [kya, saalo, kb, se, daily, dekhta, ho, ki, sa...   \n","4821                  [hi, amir, my, name, nadim, khan]   \n","4822  [i, finished, that, sentence, as, sharma, aunt...   \n","\n","                                                    lid final_lid  \n","0                                 [lang1, lang1, lang1]       eng  \n","1     [lang1, lang1, lang1, lang1, lang1, lang1, lan...       eng  \n","2                   [lang1, lang1, lang1, lang1, lang2]        bi  \n","3     [lang1, lang1, lang1, lang1, lang1, lang1, lan...       eng  \n","4     [lang1, lang1, lang1, lang1, lang1, lang1, lan...        bi  \n","...                                                 ...       ...  \n","4818                                     [lang1, lang1]       eng  \n","4819  [lang1, lang2, lang2, lang2, lang2, lang2, lan...        bi  \n","4820  [lang2, lang2, lang2, lang2, lang1, lang2, lan...        bi  \n","4821         [lang2, lang1, lang1, lang1, lang1, lang1]        bi  \n","4822  [lang1, lang1, lang1, lang1, lang1, lang1, lan...        bi  \n","\n","[4823 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-3d59c654-6e28-41c5-bf9d-557b8d5aeb8f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>lid</th>\n","      <th>final_lid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[good, vibe, tribe]</td>\n","      <td>[lang1, lang1, lang1]</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[beware, pmjohnkey, maintain, distance, from, ...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[angry, young, men, sir, ji]</td>\n","      <td>[lang1, lang1, lang1, lang1, lang2]</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[girlfriend, s, guide, to, divorce, is, the, b...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[ajay, thakur, woww, this, is, why, kabaddi, i...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4818</th>\n","      <td>[hats, off]</td>\n","      <td>[lang1, lang1]</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>4819</th>\n","      <td>[par, toda, dhyan, se, sahab, me, bhi, en, log...</td>\n","      <td>[lang1, lang2, lang2, lang2, lang2, lang2, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>4820</th>\n","      <td>[kya, saalo, kb, se, daily, dekhta, ho, ki, sa...</td>\n","      <td>[lang2, lang2, lang2, lang2, lang1, lang2, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>4821</th>\n","      <td>[hi, amir, my, name, nadim, khan]</td>\n","      <td>[lang2, lang1, lang1, lang1, lang1, lang1]</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>4822</th>\n","      <td>[i, finished, that, sentence, as, sharma, aunt...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4823 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d59c654-6e28-41c5-bf9d-557b8d5aeb8f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3d59c654-6e28-41c5-bf9d-557b8d5aeb8f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3d59c654-6e28-41c5-bf9d-557b8d5aeb8f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b1472013-7f07-4dff-8cfc-eaf1f2a5d4aa\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1472013-7f07-4dff-8cfc-eaf1f2a5d4aa')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b1472013-7f07-4dff-8cfc-eaf1f2a5d4aa button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["test_data = prepdata(valid)\n","test_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"6Q1gq0vG9UzW","executionInfo":{"status":"ok","timestamp":1700597731004,"user_tz":480,"elapsed":2515,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"e06a1518-0b17-41a8-8587-5ab96530c010"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                 words  \\\n","0    [loved, the, ending, i, could, have, offered, ...   \n","1              [viru, bahi, tusi, legend, ho, respect]   \n","2                            [we, the, fans, luv, you]   \n","3    [jahaa, panaa, tussii, gr, ho, gr, inspiration...   \n","4    [same, as, u, say, we, should, never, ignore, ...   \n","..                                                 ...   \n","739  [academicofficefail, i, appeared, for, es, end...   \n","740  [just, move, ahead, we, r, proud, of, u, kamiy...   \n","741  [i, just, dunno, how, to, talk, to, girls, but...   \n","742  [hope, to, have, a, book, release, in, chandig...   \n","743  [my, mental, condition, same, as, u, filling, ...   \n","\n","                                                   lid final_lid  \n","0    [lang1, lang1, lang1, lang1, lang1, lang1, lan...       eng  \n","1           [lang1, lang2, lang2, lang1, lang2, lang1]        bi  \n","2                  [lang1, lang1, lang1, lang1, lang1]       eng  \n","3    [lang2, lang2, lang2, lang1, lang2, lang1, lan...        bi  \n","4    [lang1, lang1, lang1, lang1, lang1, lang1, lan...       eng  \n","..                                                 ...       ...  \n","739  [lang1, lang1, lang1, lang1, lang1, lang1, lan...       eng  \n","740  [lang1, lang1, lang1, lang1, lang1, lang1, lan...        bi  \n","741  [lang1, lang1, lang1, lang1, lang1, lang1, lan...        bi  \n","742  [lang1, lang1, lang1, lang1, lang1, lang1, lan...       eng  \n","743  [lang1, lang1, lang1, lang1, lang1, lang1, lan...       eng  \n","\n","[744 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-a700387c-82fa-481c-b800-89a12ba98522\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>lid</th>\n","      <th>final_lid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[loved, the, ending, i, could, have, offered, ...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[viru, bahi, tusi, legend, ho, respect]</td>\n","      <td>[lang1, lang2, lang2, lang1, lang2, lang1]</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[we, the, fans, luv, you]</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1]</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[jahaa, panaa, tussii, gr, ho, gr, inspiration...</td>\n","      <td>[lang2, lang2, lang2, lang1, lang2, lang1, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[same, as, u, say, we, should, never, ignore, ...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>739</th>\n","      <td>[academicofficefail, i, appeared, for, es, end...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>740</th>\n","      <td>[just, move, ahead, we, r, proud, of, u, kamiy...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>741</th>\n","      <td>[i, just, dunno, how, to, talk, to, girls, but...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>bi</td>\n","    </tr>\n","    <tr>\n","      <th>742</th>\n","      <td>[hope, to, have, a, book, release, in, chandig...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>eng</td>\n","    </tr>\n","    <tr>\n","      <th>743</th>\n","      <td>[my, mental, condition, same, as, u, filling, ...</td>\n","      <td>[lang1, lang1, lang1, lang1, lang1, lang1, lan...</td>\n","      <td>eng</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>744 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a700387c-82fa-481c-b800-89a12ba98522')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a700387c-82fa-481c-b800-89a12ba98522 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a700387c-82fa-481c-b800-89a12ba98522');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-494ea1c2-e8a5-4bdc-8fd3-5dada4886f08\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-494ea1c2-e8a5-4bdc-8fd3-5dada4886f08')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-494ea1c2-e8a5-4bdc-8fd3-5dada4886f08 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["### datasets.py               # Post, Dataset, PyTorchDataset, and BatchSampler classes"],"metadata":{"id":"Ry5YH9MI4w3Y"}},{"cell_type":"code","source":["#!/usr/bin/env python\n","\n","from collections import Counter\n","from typing import Callable\n","\n","import torch\n","from torch.utils.data import Sampler, Dataset\n","from torchtext.data.functional import load_sp_model, sentencepiece_numericalizer\n","from random import shuffle\n","\n","\n","class Post:\n","    \"\"\"A single social media data instance consisting of\n","    a list of word tokens and a list of language tags\"\"\"\n","\n","    def __init__(self, words: list[str], langs: list[str]):\n","        self.words = words\n","        self.langs = langs\n","\n","    def __getitem__(self, idx):\n","        return self.words[idx], self.langs[idx]\n","\n","    def __len__(self):\n","        return len(self.words)\n","\n","\n","class LIDDataset(Dataset):\n","    def __init__(self, dataset):\n","        self.data: list[Post] = dataset\n","        self.sp_model = load_sp_model('/content/spm_user.model')\n","        self.subword_to_idx: Callable = sentencepiece_numericalizer(self.sp_model)\n","        # self.lang_to_idx: dict[str, int] = {'bn': 0, 'en': 1, 'univ': 2,\n","                                            # 'ne': 3, 'hi': 4, 'acro': 5, 'mixed': 6, 'undef': 7}\n","        self.lang_to_idx: dict[str, int] = {'lang1':0 , 'lang2': 1}\n","        self.weight_dict = self.make_weight_dict()\n","\n","    def make_weight_dict(self) -> dict:\n","        \"\"\"\n","        Instantiates the weight dict for this dataset\n","        The formula used is weight = most_frequent/lang_freq.\n","        Such that the most frequent has a frequency of 1\n","        :return: A dict with a mapping from a language to weight\n","        \"\"\"\n","        weight_dict = None\n","        if len(self.data) > 0:\n","            frequency_dict = {}\n","            label_counts = Counter([lang for sentence in self.data for lang in sentence.langs])\n","            for label in self.lang_to_idx.keys():\n","                frequency_dict[label] = label_counts[label]\n","            most_frequent = max(frequency_dict.values())\n","            weight_dict = {label: (most_frequent / frequency_dict[label]) if frequency_dict[label] != 0 else 0\n","                           for label in frequency_dict.keys()}\n","        return weight_dict\n","\n","    def __getitem__(self, idx) -> tuple[list[str], list[str]]:\n","        idx_item = self.data[idx]\n","        assert len(idx_item.words) == len(idx_item.langs)\n","        return idx_item.words, idx_item.langs\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def get_tag_set(self) -> list:\n","        \"\"\"returns ordered list of language labels in the dataset\n","        Returns:\n","            list -- Ordered list of language labels\n","        \"\"\"\n","        langs = list(self.lang_to_idx.keys())\n","        langs.sort()\n","        return langs\n","\n","    def get_lang_to_idx(self) -> dict:\n","        \"\"\"get dict from lang to id, ordered alphabetically\n","        Returns:\n","            dict -- For converting language code to an id\n","        \"\"\"\n","        lang_to_idx = {}\n","        for lang in self.get_tag_set():\n","            lang_to_idx[lang] = len(lang_to_idx)\n","        return lang_to_idx\n","\n","\n","class PyTorchLIDDataSet(Dataset):\n","    \"\"\"\n","    PyTorch-specific wrapper that converts items to PyTorch tensors.\n","    \"\"\"\n","\n","    def __init__(self, decoree: LIDDataset):\n","        self.data = []\n","        self.all_post_lens = []\n","        if decoree is not None:\n","            self.decoree = decoree\n","        self.subword_to_idx = decoree.subword_to_idx\n","        self.lang_to_idx = decoree.lang_to_idx\n","        self.tensorify_all()\n","\n","    def __getitem__(self, idx):\n","        if not isinstance(idx, list):\n","            return self.data[idx]\n","        txt = []\n","        mask = []\n","        label = []\n","        for i in idx:\n","            item = self.data[i]\n","            txt.append(item[0])\n","            mask.append(item[1])\n","            label.append(item[2])\n","\n","        txts = torch.stack(txt)\n","        masks = torch.stack(mask)\n","        labels = torch.stack(label)\n","\n","        return txts, masks, labels\n","\n","    def make_weight_dict(self) -> dict:\n","        return self.decoree.make_weight_dict()\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def get_tag_set(self) -> list:\n","        return self.decoree.get_tag_set()\n","\n","    def get_lang_to_idx(self) -> dict:\n","        \"\"\"get dict from lang to id, ordered alphabetically\n","        Returns:\n","            dict -- For converting language code to an id\n","        \"\"\"\n","        return self.decoree.get_lang_to_idx()\n","\n","    def tensorify(self, data_point: tuple[list[str], list[str]]):\n","        words, langs = data_point\n","        self.all_post_lens.append(len(words))\n","        word_id = list(self.subword_to_idx(words))\n","        lang_id = [self.lang_to_idx[lang] for lang in langs]\n","\n","        # The first subword is assigned the true label, all other subwords are assigned the dummy label -1\n","        lang_id_pad = [[lang_id[word_num]] + [-1] * (len(word_id[word_num]) - 1) for word_num in range(len(word_id))]\n","\n","        word_ids_flat = [w_id for word in word_id for w_id in word]\n","        lang_ids_flat = [l_id for lang in lang_id_pad for l_id in lang]\n","\n","        mask_nest = [[True] + [False] * (len(word_id[num]) - 1) for num in range(len(word_id))]\n","        mask = [idx for word in mask_nest for idx in word]\n","\n","        return torch.tensor(word_ids_flat, dtype=torch.long), \\\n","               torch.tensor(mask, dtype=torch.bool), \\\n","               torch.tensor(lang_ids_flat, dtype=torch.long)\n","\n","    def tensorify_all(self):\n","        new_data = []\n","        for elem in self.decoree:\n","            new_data.append(self.tensorify(elem))\n","        self.data = new_data\n","\n","    def set_lang_to_idx(self, l_to_idx):\n","        self.lang_to_idx = l_to_idx\n","        self.decoree.lang_to_idx = l_to_idx\n","\n","    def set_subword_to_idx(self, s_to_idx):\n","        self.subword_to_idx = s_to_idx\n","        self.decoree.char_to_idx = s_to_idx\n","\n","\n","# ----------------------------------------------------------------------------------------------------------------------\n","# Based on https://github.com/chrisvdweth/ml-toolkit/blob/master/pytorch/utils/data/text/dataset.py\n","class BatchSampler(Sampler):\n","    \"\"\"\n","    This class creates batches containing equal length examples.\n","    \"\"\"\n","\n","    def __init__(self, batch_size, inputs):\n","        self.batch_size = batch_size\n","        self.input = inputs\n","        self.batch_list = self._generate_batch_map()\n","        self.num_batches = len(self.batch_list)\n","\n","    def _generate_batch_map(self):\n","        batch_map = {}\n","        for idx, item in enumerate(self.input):\n","            length = len(item[0])\n","            if length not in batch_map:\n","                batch_map[length] = [idx]\n","            else:\n","                batch_map[length].append(idx)\n","        # Use batch_map to split indices into batches of equal size\n","        # e.g., for batch_size=3, batch_list = [[23,45,47], [49,50,62], [63,65,66], ...]\n","        batch_list = []\n","        for length, indices in batch_map.items():\n","            for group in [indices[i:(i + self.batch_size)] for i in range(0, len(indices), self.batch_size)]:\n","                batch_list.append(group)\n","        return batch_list\n","\n","    def batch_count(self):\n","        return self.num_batches\n","\n","    def __len__(self):\n","        return self.num_batches\n","\n","    def __iter__(self):\n","        shuffle(self.batch_list)\n","        for i in self.batch_list:\n","            yield i"],"metadata":{"id":"pXggjcS-4Cgo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### data_loading.py -  functions for loading raw files and training the sentencepiece model\n"],"metadata":{"id":"4vp6lnD64k8F"}},{"cell_type":"code","source":["import random\n","from collections import Counter\n","from typing import Optional\n","from torchtext.data import generate_sp_model\n","import re\n","\n","# from datasets import Post\n","from pathlib import Path\n","\n","\n","def load_raw_post(filepath: Optional[Path]) -> list[Post]:\n","    \"\"\"\n","    Reads the raw data from a file and converts it into a list of Post objects.\n","    This will later be shuffled and written into three separate files for training, development, and testing.\n","    :return: one list of Post objects\n","    \"\"\"\n","    all_data = []\n","    words, langs = [], []\n","\n","    if filepath is not None:\n","        with open(filepath) as file:\n","            for line in file:\n","                line = line.rstrip()\n","                if len(line) == 0:\n","                    if len(words) != 0:\n","                        all_data.append(Post(words, langs))\n","                        words, langs = [], []\n","                else:\n","                    word, lang, _ = line.split('\\t')\n","                    if '+' in lang:\n","                        lang = 'mixed'\n","                    word = re.sub(r'(.)\\1{2,}', r\"\\1\\1\", word.lower())\n","                    words.append(word)\n","                    langs.append(lang)\n","    return all_data\n","\n","from sklearn.model_selection import train_test_split\n","\n","def get_train_dev_test(data_filepath: str) -> tuple[list[Post], list[Post], list[Post]]:\n","    \"\"\"\n","    Reads data from the provided directory path and splits the data into train, dev, and test\n","    :return: 3 lists of posts representing the train data, development data, and test data\n","    \"\"\"\n","    # train = load_prepped_file(data_filepath + 'train.txt')\n","    # dev = load_prepped_file(data_filepath + 'dev.txt')\n","    # test = load_prepped_file(data_filepath + 'test.txt')\n","\n","    train_data ,validation_data = train_test_split(dx,test_size=0.5)\n","\n","    train = load_prepped_file(train_data)\n","    dev = load_prepped_file(validation_data)\n","    test = load_prepped_file(test_data)\n","\n","    return train, dev, test\n","\n","\n","def write_prep_data(dirpath: str, data: tuple[list[Post], list[Post], list[Post]]) -> None:\n","    \"\"\"\n","    Takes in raw train, dev and test data, and writes to a file with one post per line,\n","    with tokens and language tags split with a backslash\n","    :return: 3 lists of posts representing the train data, development data, and test data\n","    \"\"\"\n","\n","    fnames = [f'{dirpath}train.txt', f'{dirpath}dev.txt', f'{dirpath}test.txt']\n","    for fname, data_chunk in zip(fnames, data):\n","        with open(fname, 'w') as file:\n","            for post in data_chunk:\n","                tagged = ['/'.join((word, tag)) for word, tag in zip(post.words, post.langs)]\n","                file.write(\" \".join(tagged) + '\\n')\n","\n","\n","# def load_prepped_file(filepath: str) -> list[Post]:\n","#     \"\"\"\n","#     Reads the prepared data from one file and converts it into a list of Post objects\n","#     :return: one list of Post objects\n","#     \"\"\"\n","#     data = []\n","#     with open(filepath) as f:\n","#         for line in f:\n","#             line = line.rstrip().split(' ')\n","#             if len(line) > 0:\n","#                 words = [pair.rsplit('/', 1)[0] for pair in line]\n","#                 langs = [pair.rsplit('/', 1)[1] for pair in line]\n","#                 assert len(words) == len(langs)\n","#                 data.append(Post(words, langs))\n","#     return data\n","\n","def load_prepped_file(df):\n","  data = []\n","  # print(df)\n","  for index, row in df.iterrows():\n","      # print(row)\n","      if len(row['words']) > 0:\n","          words = row['words']\n","          lid = row['lid']\n","          assert len(words) == len(lid)\n","          data.append(Post(words, lid))\n","  return data\n","\n","def gen_sentpiece_model(vocab_size,\n","                        model_type: str = 'unigram',\n","                        train_filepath: str = '/content/drive/MyDrive/NLP_Project/train.txt',\n","                        output_filepath: str = '/content/drive/MyDrive/NLP_Project/sp_source_data.txt'):\n","    \"\"\"\n","    Uses training data to generate sentencepiece source data. Creates sentencepiece model of provided\n","    vocab size and returns the sentencepiece model\n","    :return: sentencepiece model\n","    \"\"\"\n","    # train_data = load_prepped_file(train_filepath)\n","    train_data = dx\n","    with open(output_filepath, 'w') as f:\n","        # for post in train_data:\n","        #     f.write(' '.join(post.words) + '\\n')\n","        for row in dx['words']:\n","          # print(row)\n","          f.write(' '.join(row)+ '\\n')\n","\n","    generate_sp_model(output_filepath, vocab_size=vocab_size, model_prefix='./spm_user', model_type=model_type)\n","\n","\n","def print_stats(filepaths: list[Path]) -> None:\n","    langs = ['bn', 'en', 'univ', 'ne', 'hi', 'acro', 'mixed', 'undef']\n","\n","    for f in filepaths:\n","        dataset: list[Post] = load_raw_post(f)\n","        lang_counts = Counter(lang for post in dataset for lang in post.langs)\n","        num_tokens = sum([len(post) for post in dataset])\n","        num_utts = str(len(dataset))\n","        lang_percs = \"\\t\".join([\"{:.2%}\".format(lang_counts[lang] / num_tokens) for lang in langs])\n","        print(f'{f.name}\\t\\t{num_tokens}\\t{num_utts}\\t{lang_percs}')\n","\n","\n","def split_write_data(write_path, all_data: list[Post]) -> tuple[list[Post], list[Post], list[Post]]:\n","    random.shuffle(all_data)\n","    # 60:20:20 split\n","    twenty_perc = int(len(all_data) * 0.2)\n","    train_end = twenty_perc * 3\n","    test_end = train_end + twenty_perc\n","\n","    train = all_data[: train_end]\n","    test = all_data[train_end: test_end]\n","    dev = all_data[test_end:]\n","\n","    write_prep_data(write_path, (train, dev, test))\n","    return train, dev, test\n","\n","\n","def print_cmis(filepaths: list[Path]) -> None:\n","    for f in filepaths:\n","        dataset: list[Post] = load_raw_post(f)\n","        cmis = \"\\t\".join(compute_cmi(dataset))\n","        print(f'{f.name}\\t\\t{cmis}')\n","\n","\n","def compute_cmi(dataset: list[Post]):\n","    lang_tags = {'bn', 'en', 'hi', 'mixed'}\n","    non_lang_tags = {'univ', 'acro', 'ne', 'undef'}\n","\n","    all_cmis = []\n","    num_tokens = 0\n","\n","    for post in dataset:\n","        num_tokens += len(post)\n","        lang_counts = Counter(lang for lang in post.langs if lang in lang_tags)\n","        non_lang_counts = Counter(tag for tag in post.langs if tag in non_lang_tags)\n","\n","        if len(lang_counts) == 0:\n","            cmi = 0\n","        else:\n","            max_wi = lang_counts.most_common(1)[0][1]\n","            denom = len(post) - sum(non_lang_counts.values())\n","            cmi = 100 * (1 - (max_wi / denom))\n","        all_cmis.append(cmi)\n","\n","    num_tokens = str(num_tokens)\n","    num_utts = str(len(dataset))\n","    all_cmi = \"{:.4}\".format(sum(all_cmis) / len(all_cmis))\n","    mixed_cmi = \"{:.4}\".format(sum(all_cmis) / (len(all_cmis) - all_cmis.count(0)))\n","    code_mix_perc = \"{:.2%}\".format((len(all_cmis) - all_cmis.count(0)) / len(all_cmis))\n","\n","    return num_tokens, num_utts, all_cmi, mixed_cmi, code_mix_perc\n","\n","\n","def unique_tokens(data: list[Post]) -> dict[str, set[str]]:\n","    bn_wordset = {post.words[i] for post in data for i in range(len(post)) if post.langs[i] == 'bn'}\n","    en_wordset = {post.words[i] for post in data for i in range(len(post)) if post.langs[i] == 'en'}\n","    return {'bn': bn_wordset, 'en': en_wordset}\n","\n","\n","def perc_tok_overlap(data_comp: list[Post], data_test: list[Post]):\n","    comp_set = unique_tokens(data_comp)\n","    test_set = unique_tokens(data_test)\n","\n","    for lang, words in test_set.items():\n","        overlap_words = words & comp_set[lang]\n","        perc_overlap = len(overlap_words) / len(words)\n","        print(lang, \"{:.2%}\".format(perc_overlap))\n","\n","\n","VOCAB_SIZE = 7000\n","\n","\n","# def main():\n","    # data_sources = sorted([path for path in Path('./data').iterdir()])\n","    # data = [post for f in data_sources for post in load_raw_post(f)]\n","    # # print_stats(data_sources)\n","    # # print_cmis(data_sources)\n","    # prep_path = './train_dev_test_data/'\n","    # split_write_data(prep_path, data)\n","\n","    # train, dev, test = get_train_dev_test(prep_path)\n","    # print(\"Percentage of test tokens also in dev\")\n","    # perc_tok_overlap(dev, test)\n","    # print(\"Percentage of test tokens also in train\")\n","    # perc_tok_overlap(train, test)\n","\n","gen_sentpiece_model(vocab_size=VOCAB_SIZE, model_type='unigram')\n","\n","\n","# if __name__ == \"__main__\":\n","#     main()"],"metadata":{"id":"x05X14NG37kY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### GETTING EMBEDDINGS READY"],"metadata":{"id":"TCHz2r4WjuNd"}},{"cell_type":"code","source":["train, dev, test = get_train_dev_test('/content/drive/MyDrive/NLP_Project/')\n","train_dataset = LIDDataset(train)\n","dev_dataset = LIDDataset(dev)\n","test_dataset = LIDDataset(test)\n","\n","train_data_converted = PyTorchLIDDataSet(train_dataset)\n","dev_converted = PyTorchLIDDataSet(dev_dataset)"],"metadata":{"id":"EoKASmzXj0BU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_vocab_file(file_path):\n","    word_probabilities = {}\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        for line in file:\n","            word, prob = line.strip().split('\\t')\n","            word_probabilities[word] = float(prob)\n","    return word_probabilities\n","\n","# Example file path\n","file_path = '/content/spm_user.vocab'\n","\n","# Read vocabulary file\n","word_probabilities = read_vocab_file(file_path)"],"metadata":{"id":"5Ci_T_wZ0zzS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_vectors = {}\n","for word, prob in word_probabilities.items():\n","    vector = np.random.rand(128) if prob == 0 else np.random.randn(128) * (-prob)\n","    word_vectors[word] = vector\n","\n","# Write word vectors to a file in GloVe-like format\n","with open('/content/drive/MyDrive/NLP_Project/custom_embedding.txt', 'w', encoding='utf-8') as file:\n","    for word, vector in word_vectors.items():\n","        file.write(f\"{word} {' '.join(str(x) for x in vector)}\\n\")"],"metadata":{"id":"Z_BqperByEou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_converted[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGthJAJVqho-","executionInfo":{"status":"ok","timestamp":1700597735419,"user_tz":480,"elapsed":24,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"7beaf097-c5fb-4c7e-9391-fb95c3cef8f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([ 818, 1211,    3,   78]),\n"," tensor([ True,  True, False,  True]),\n"," tensor([ 0,  0, -1,  0]))"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["vocab,embeddings = [],[]\n","with open('/content/drive/MyDrive/NLP_Project/custom_embedding.txt','rt') as fi:\n","    full_content = fi.read().strip().split('\\n')\n","for i in range(len(full_content)):\n","    i_word = full_content[i].split(' ')[0]\n","    i_embeddings = [float(val) for val in full_content[i].split(' ')[1:]]\n","    vocab.append(i_word)\n","    embeddings.append(i_embeddings)"],"metadata":{"id":"70ne4a-FHq11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_npa = np.array(vocab)\n","embs_npa = np.array(embeddings)"],"metadata":{"id":"IznVCK83LQkw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(vocab_npa)"],"metadata":{"id":"hb4b3HQkds9h","executionInfo":{"status":"ok","timestamp":1700597736904,"user_tz":480,"elapsed":28,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"779a3f6f-0fb5-4a2d-dc8e-f707acdc8e37"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7000"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["embs_npa.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zh7RR5a75cO7","executionInfo":{"status":"ok","timestamp":1700597736905,"user_tz":480,"elapsed":24,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"fe2ea433-217a-4885-e965-dded179a8110"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7000, 128)"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["vocab_npa = np.insert(vocab_npa, 0, '[PAD]')\n","vocab_npa = np.insert(vocab_npa, 1, '[UNK]')\n","print(vocab_npa[:10])\n","\n","pad_emb_npa = np.zeros((1,embs_npa.shape[1]))   #embedding for '<pad>' token.\n","unk_emb_npa = np.mean(embs_npa,axis=0,keepdims=True)    #embedding for '<unk>' token.\n","\n","#insert embeddings for pad and unk tokens at top of embs_npa.\n","embs_npa = np.vstack((pad_emb_npa,unk_emb_npa,embs_npa))\n","print(embs_npa.shape)"],"metadata":{"id":"51wUtjf7LYJx","executionInfo":{"status":"ok","timestamp":1700597736905,"user_tz":480,"elapsed":17,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"69168402-d6ea-49b4-9fc8-ddee56af487f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['[PAD]' '[UNK]' '<unk>' '<s>' '</s>' 's' '▁the' '▁' '▁to' 'e']\n","(7002, 128)\n"]}]},{"cell_type":"code","source":["# with open('/content/drive/MyDrive/NLP_Project/csci544_hw4/vocab_npa.npy','wb') as f:\n","#     np.save(f,vocab_npa)\n","\n","# with open('/content/drive/MyDrive/NLP_Project/csci544_hw4/embs_npa.npy','wb') as f:\n","#     np.save(f,embs_npa)"],"metadata":{"id":"oiDUB109NbP1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### lid_model.py              # full language ID model and training loop"],"metadata":{"id":"s-pvwooc5CMj"}},{"cell_type":"code","source":["import time\n","import re\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","\n","# from datasets import BatchSampler, PyTorchLIDDataSet\n","# from data_loading import VOCAB_SIZE\n","\n","\n","def correct_predictions(scores, masks, labels):\n","    pred = torch.argmax(scores, dim=1)\n","    masked_pred = torch.masked_select(pred, masks)\n","    masked_labels = torch.masked_select(labels, masks)\n","    return (masked_pred == masked_labels).sum()\n","\n","\n","class LIDModel(nn.Module):\n","    def __init__(self, subword_to_idx, lang_to_idx):\n","        # Subword_to_idx is a function that converts a subword to a number, and converts unknown tokens to 0\n","        # Lang_to_idx is a map that converts a language to a number\n","        self.subword_to_idx = subword_to_idx\n","        self.lang_to_idx = lang_to_idx\n","        self.idx_to_lang = dict([(value, key) for key, value in lang_to_idx.items()])\n","        self.vocab_size = VOCAB_SIZE\n","        self.lang_set_size = len(lang_to_idx)\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        super(LIDModel, self).__init__()\n","\n","    def pad_collate(self, batch):\n","        (words, masks, labels) = batch[0]\n","        words = words.to(self.device)\n","        masks = masks.to(self.device)\n","        labels = labels.to(self.device)\n","        return words, masks, labels\n","\n","    def prepare_sentence(self, sentence: list[str]) -> tuple[torch.tensor, torch.tensor]:\n","        norm_sent = [re.sub(r'(.)\\1{2,}', r\"\\1\\1\", word.lower()) for word in sentence]\n","        word_id = list(self.subword_to_idx([word for word in norm_sent]))\n","        mask_nest = [[True] + [False] * (len(word_id[num]) - 1) for num in range(len(word_id))]\n","\n","        word_ids_flat = [w_id for word in word_id for w_id in word]\n","        mask_flat = [idx for word in mask_nest for idx in word]\n","\n","        id_tensor = torch.tensor(word_ids_flat, dtype=torch.long, device=self.device).view(1, len(word_ids_flat))\n","        mask_tensor = torch.tensor(mask_flat, dtype=torch.bool, device=self.device)\n","\n","        return id_tensor, mask_tensor\n","\n","    def forward(self, sentence: list[str]):\n","        raise NotImplemented\n","\n","    def predict(self, sentence: list[str]) -> list[tuple[str, str]]:\n","        self.eval()\n","        prep_sent, mask = self.prepare_sentence(sentence)\n","\n","        feats = self(prep_sent).transpose(1, 2)  # shape (batch_size, seq_len, num_labels)\n","        feats_smax = F.softmax(feats, dim=-1).squeeze()  # softmaxing over each word\n","\n","        preds = torch.argmax(feats_smax, dim=-1)\n","        masked_preds = torch.masked_select(preds, mask)\n","        lang_preds = [self.idx_to_lang[pred.item()] for pred in masked_preds]\n","\n","        zipped_preds = [(word, lang) for word, lang in zip(sentence, lang_preds)]\n","\n","        self.train()\n","        return zipped_preds\n","        # return Post(sentence, lang_preds)\n","\n","    def rank(self, sentence: list[str]) -> dict[str: list[float]]:\n","        self.eval()\n","        prep_sent, mask = self.prepare_sentence(sentence)\n","        feats = self(prep_sent).transpose(1, 2)  # shape (batch_size, seq_len, num_labels)\n","        feats_smax = F.softmax(feats, dim=-1).squeeze()  # softmaxing over each word\n","        feats_smax = feats_smax.unsqueeze(0) if len(list(feats_smax.size())) < 2 else feats_smax\n","\n","        lang_to_confs = {lang: [] for lang in self.lang_to_idx.keys()}\n","        for feat, f_mask in zip(feats_smax, mask):\n","            if f_mask:\n","                for lang, lang_idx in self.lang_to_idx.items():\n","                    lang_to_confs[lang].append(feat[lang_idx].item())\n","        self.train()\n","        return lang_to_confs\n","\n","    def fit(self, train_dataset: PyTorchLIDDataSet, dev_dataset: PyTorchLIDDataSet,\n","            optimizer, epochs=3, batch_size=64, weight_dict=None):\n","        test_sampler = BatchSampler(batch_size, dev_dataset)\n","        dataloader_dev = DataLoader(dev_dataset,\n","                                    shuffle=False,\n","                                    drop_last=False,\n","                                    collate_fn=self.pad_collate,\n","                                    sampler=test_sampler)\n","\n","        weights = None\n","        if weight_dict is not None:\n","            weights = torch.zeros(len(weight_dict)).to(self.device)\n","            for lang in weight_dict:\n","                indx = self.lang_to_idx[lang]\n","                weights[indx] = weight_dict[lang]\n","\n","        best_dev = {'accuracy': 0, 'epoch': 0}\n","\n","        # Index of the dummy label is -1\n","        loss_train = nn.CrossEntropyLoss(weight=weights, ignore_index=-1)\n","        loss_dev = nn.CrossEntropyLoss(ignore_index=-1)\n","\n","        print(f\"Running for {epochs} epochs\")\n","        for epoch in range(epochs):\n","            self.train()\n","            avg_total_loss, num_correct_preds = 0, 0\n","            epoch_start_time = time.time()\n","            #\n","            print(batch_size)\n","            print(len(train_dataset))\n","            #\n","            sampler = BatchSampler(batch_size, train_dataset)\n","            dataloader_train = DataLoader(train_dataset,\n","                                          shuffle=False,\n","                                          drop_last=False,\n","                                          collate_fn=self.pad_collate,\n","                                          sampler=sampler)\n","\n","            # Logit is the pre-softmax scores\n","            for idx, batch in enumerate(tqdm(dataloader_train, leave=False)):\n","                optimizer.zero_grad()\n","                tensor_sentences, masks, labels = batch\n","                logit = self(tensor_sentences)\n","                loss_nll = loss_train(logit, labels)\n","                num_correct_preds += correct_predictions(logit, masks, labels)\n","                loss = loss_nll\n","                avg_total_loss += loss.item()\n","                loss.backward()\n","                optimizer.step()\n","            avg_total_loss /= sampler.batch_count()\n","\n","            train_num_tokens = sum(train_dataset.all_post_lens)\n","            accuracy = (num_correct_preds / train_num_tokens).item()\n","\n","            print(f\"\\nAverage training error in epoch {epoch + 1}: {avg_total_loss:.5f} \"\n","                  f\"and training accuracy: {accuracy:.4f}\")\n","            step_num = epoch\n","            print(\"Training Accuracy:\", accuracy, step_num)\n","            print(\"Training Loss:\", avg_total_loss, step_num)\n","            self.eval()\n","            # Test model\n","            avg_total_loss, num_correct_preds = 0, 0\n","            for _, batch in enumerate(tqdm(dataloader_dev, leave=False)):\n","                tensor_sentences, masks, labels = batch\n","                logit = self(tensor_sentences)\n","                loss_nll = loss_dev(logit, labels)\n","                num_correct_preds += correct_predictions(logit, masks, labels)\n","                avg_total_loss += loss_nll.item()\n","            avg_total_loss /= test_sampler.batch_count()\n","\n","            dev_num_tokens = sum(dev_dataset.all_post_lens)\n","            accuracy = (num_correct_preds / dev_num_tokens).item()\n","\n","            print(f\"\\nAverage total loss dev: {avg_total_loss:.5f}, accuracy: {accuracy:.4f}, \")\n","            print(\"Dev Accuracy:\", accuracy, step_num)\n","            print(\"Dev Loss:\", avg_total_loss, step_num)\n","\n","            if accuracy > best_dev['accuracy']:\n","                best_dev['accuracy'] = accuracy\n","                best_dev['epoch'] = epoch\n","            if accuracy > 0.92:\n","                self.save_model(\"E\" + str(epoch))\n","            print(\"Time spent in epoch {0}: {1:.2f} \".format(epoch + 1, time.time() - epoch_start_time))\n","\n","        print(f\"\\nBest dev accuracy: {best_dev['accuracy']} found in EPOCH: {best_dev['epoch']}\")\n","\n","    def save_model(self, fileending=\"\"):\n","        \"\"\"Saves a pytorch model fully\n","        \"\"\"\n","        required_model_information = {'model_state_dict': self.state_dict()}\n","        fname = \"./trained_model_dict\" + fileending + \".pth\"\n","        torch.save(required_model_information, fname)"],"metadata":{"id":"Oi_U0d5j4IrW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### lstm_model.py             # LSTM model that initializes as layers, implements forward method"],"metadata":{"id":"7Po-69Av5KDf"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","# from lid_model import LIDModel\n","\n","\n","DROPOUT = 0.4\n","\n","\n","class LSTMLIDModel(LIDModel):\n","    def __init__(self, subword_to_idx, lang_to_idx, embedding_dim=300, hidden_dim=300, layers=1):\n","        super(LSTMLIDModel, self).__init__(subword_to_idx, lang_to_idx)\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = layers\n","        self.embedding_dim = embedding_dim\n","\n","        self.embedding = nn.Embedding(self.vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=layers, bidirectional=True, batch_first=True)\n","        self.linear = nn.Linear(hidden_dim * 2, self.lang_set_size)\n","        self.dropout = nn.Dropout(DROPOUT)\n","        self.to(self.device)\n","\n","    def forward(self, sentence):\n","        embed = self.embedding(sentence)\n","        embed = self.dropout(embed)\n","        outputs, _ = self.lstm(embed)\n","        outputs = self.linear(outputs)\n","        return outputs.transpose(1, 2)\n","\n","    def save_model(self, fileending=\"\"):\n","        \"\"\"Saves a dict containing statedict and other required model parameters and adds it as artifact\n","        Arguments:\n","        \"\"\"\n","        required_model_information = {'model_state_dict': self.state_dict(),\n","                                      'embedding_dim': self.embedding_dim,\n","                                      'hidden_dim': self.hidden_dim,\n","                                      'layers': self.num_layers}\n","        fname = \"/content/drive/MyDrive/NLP_Project/trained_LID_model\" + fileending + \".pth\"\n","        torch.save(required_model_information, fname)"],"metadata":{"id":"Prk9OvkU4Max"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### train_test_model.py       # functions for training and testing the model, used in run_training.py"],"metadata":{"id":"86FDpkq15Xux"}},{"cell_type":"code","source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import numpy as np\n","from tqdm import tqdm\n","\n","# from lid_model import LIDModel\n","# from datasets import LIDDataset, PyTorchLIDDataSet, Post\n","# from data_loading import get_train_dev_test\n","from typing import Optional\n","\n","\n","def test_model(data_set, model: LIDModel) -> tuple[list[Post], np.ndarray]:\n","    model.eval()\n","    lang_to_idx = model.lang_to_idx\n","    data_loader = DataLoader(data_set, batch_size=1)\n","\n","    conf_mat = np.zeros((len(lang_to_idx), len(lang_to_idx)))\n","    all_tagged_sents = []\n","\n","    for i, item in enumerate(tqdm(data_loader, leave=False)):\n","        tokens, langs = item\n","        tokens = [w[0] for w in tokens]\n","        gold_labels = [lang[0] for lang in langs]\n","        pred_labels = [label for _, label in model.predict(tokens)]\n","        all_tagged_sents.append(Post(tokens, pred_labels))\n","\n","        for pred, gold in zip(pred_labels, gold_labels):\n","            conf_mat[lang_to_idx[pred]][lang_to_idx[gold]] += 1\n","\n","    return all_tagged_sents, conf_mat\n","\n","\n","def save_metrics(conf_mat, lang_labels):\n","    \"\"\"Saves metrics as a .txt file\n","    Arguments:\n","        conf_mat  -- confusion matrix across dataset\n","        lang_labels -- list of language labels corresponding with confusion matrix heading\n","    \"\"\"\n","    accuracy = conf_mat.trace() / np.sum(conf_mat)\n","    precision = np.diag(conf_mat) / np.sum(conf_mat, axis=1)\n","    recall = np.diag(conf_mat) / np.sum(conf_mat, axis=0)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","\n","    fname = \"/content/drive/MyDrive/NLP_Project/test_metrics.txt\"\n","    with open(fname, 'w') as f:\n","        f.write(\"\\nAccuracy:\\t\" + \"\\t\".join([\"{:.4%}\".format(accuracy)]))\n","        f.write(\"\\nLabels:\\t\" + \"\\t\".join(lang_labels))\n","        f.write(\"\\nPrecision:\\t\" + \"\\t\".join([\"{:.4%}\".format(prec) for prec in precision.tolist()]))\n","        f.write(\"\\nRecall:\\t\" + \"\\t\".join([\"{:.4%}\".format(rec) for rec in recall.tolist()]))\n","        f.write(\"\\nF1:\\t\" + \"\\t\".join([\"{:.4%}\".format(f) for f in f1.tolist()]))\n","        f.close()\n","\n","\n","def save_preds(predictions: list[Post]):\n","    \"\"\"Saves predictions as a .txt file\n","    Arguments:\n","        preds  -- list of tagged sentences to save\n","    \"\"\"\n","    fname = \"/content/drive/MyDrive/NLP_Project/test_predictions.txt\"\n","    with open(fname, 'w') as f:\n","        for post in predictions:\n","            tagged = ['/'.join((word, tag)) for word, tag in zip(post.words, post.langs)]\n","            f.write(\" \".join(tagged) + \"\\n\")\n","        f.close()\n","\n","\n","def train_model(data_set: PyTorchLIDDataSet, test_dataset: PyTorchLIDDataSet, lidmodel: 'LIDModel',\n","                training_params, weight_dict: Optional[dict] = None):\n","    optimizer, weight_decay, lr, batch_size, epochs = training_params\n","    if optimizer.strip().lower() == \"sgd\":\n","        opti = optim.SGD(lidmodel.parameters(), lr=lr, weight_decay=weight_decay)\n","    else:\n","        opti = optim.AdamW(params=lidmodel.parameters())\n","    lidmodel.fit(data_set, test_dataset, opti, epochs=epochs, weight_dict=weight_dict, batch_size=batch_size)\n","\n","\n","def run_training(model, training_params, to_train=True, eval_on_test=False):\n","\n","    train, dev, test = get_train_dev_test('/content/drive/MyDrive/NLP_Project/')\n","\n","    train_dataset = LIDDataset(train)\n","    dev_dataset = LIDDataset(dev)\n","    test_dataset = LIDDataset(test)\n","\n","    train_data_converted = PyTorchLIDDataSet(train_dataset)\n","    dev_converted = PyTorchLIDDataSet(dev_dataset)\n","\n","    weight_dict = train_dataset.weight_dict\n","    print(len(train_data_converted))\n","    print(len(dev_converted))\n","    if to_train:\n","        print(\"Training model\")\n","        train_model(train_data_converted, dev_converted, model,\n","                    training_params=training_params, weight_dict=weight_dict)\n","\n","    print(\"Testing model\")\n","    dataset_for_eval = test_dataset if eval_on_test else dev_dataset\n","    predictions, confusion_mat = test_model(data_set=dataset_for_eval, model=model)\n","\n","    print(\"Saving model\")\n","    model.save_model()\n","\n","    print(\"Saving predictions\")\n","    save_preds(predictions)\n","    save_metrics(confusion_mat, list(dataset_for_eval.lang_to_idx.keys()))"],"metadata":{"id":"fMzgMYxI4RqG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### run_training.py           # adjust hyperparameters and train the full model"],"metadata":{"id":"5rsF_ymr5Qy6"}},{"cell_type":"code","source":["# Code is based on https://github.com/AU-DIS/LSTM_langid\n","from typing import Optional, Callable\n","\n","import torch\n","from torchtext.data import sentencepiece_numericalizer, load_sp_model\n","# from train_test_model import run_training\n","# from lstm_model import LSTMLIDModel\n","\n","\n","def load_LSTM_model(pretrained_model_path: Optional[str],\n","                    subword_to_idx: Callable,\n","                    lang_to_idx: dict,\n","                    hidden_dim,\n","                    embedding_dim,\n","                    num_lstm_layers):\n","    if pretrained_model_path is not None:\n","        model_dict = torch.load(pretrained_model_path)\n","        lstm_model = LSTMLIDModel(subword_to_idx=subword_to_idx,\n","                                  lang_to_idx=lang_to_idx,\n","                                  hidden_dim=model_dict['hidden_dim'],\n","                                  embedding_dim=model_dict['embedding_dim'],\n","                                  layers=model_dict['layers'])\n","        lstm_model.load_state_dict(model_dict['model_state_dict'])\n","\n","    else:\n","        lstm_model = LSTMLIDModel(subword_to_idx=subword_to_idx,\n","                                  lang_to_idx=lang_to_idx,\n","                                  hidden_dim=hidden_dim,\n","                                  embedding_dim=embedding_dim,\n","                                  layers=num_lstm_layers)\n","    return lstm_model\n","\n","\n","def main(pretrained_model,\n","         epochs,\n","         weight_decay,\n","         batch_size,\n","         lr,\n","         optimizer,\n","         eval_on_test=False):\n","    training_params = optimizer, weight_decay, lr, batch_size, epochs\n","    numericalizer = sentencepiece_numericalizer(load_sp_model('/content/spm_user.model'))\n","    # lang_to_idx = {'bn': 0, 'en': 1, 'univ': 2, 'ne': 3, 'hi': 4, 'acro': 5, 'mixed': 6, 'undef': 7}\n","    lang_to_idx = {'lang1':0 , 'lang2': 1}\n","\n","    lstm_model = load_LSTM_model(pretrained_model_path=pretrained_model,\n","                                 subword_to_idx=numericalizer,\n","                                 lang_to_idx=lang_to_idx,\n","                                 hidden_dim=HIDDEN_DIM,\n","                                 embedding_dim=EMBEDDING_DIM,\n","                                 num_lstm_layers=NUM_LSTM_LAYERS)\n","    to_train = pretrained_model is None\n","\n","    run_training(lstm_model, training_params, to_train, eval_on_test)\n","\n","\n","# PRETRAINED_MODEL = '/content/drive/MyDrive/NLP_Project/trained_LID_model.pth'\n","PRETRAINED_MODEL = None\n","\n","EPOCHS = 40\n","SEED = 42\n","HIDDEN_DIM = 400\n","EMBEDDING_DIM = 400\n","NUM_LSTM_LAYERS = 1\n","OPTIMIZER = 'adam'\n","LR = 0.1\n","WEIGHT_DECAY = 0.00001\n","BATCH_SIZE = 64\n","EVAL_ON_TEST = True\n","\n","\n","# if __name__ == \"__main__\":\n","print(f'PRETRAINED_MODEL = {PRETRAINED_MODEL}\\n'\n","      f'EPOCHS = {EPOCHS}\\n'\n","      f'HIDDEN_DIM = {HIDDEN_DIM}\\n'\n","      f'EMBEDDING_DIM = {EMBEDDING_DIM}\\n'\n","      f'NUM_LSTM_LAYERS = {NUM_LSTM_LAYERS}\\n'\n","      f'OPTIMIZER = {OPTIMIZER}\\n'\n","      # f'LR = {LR}\\n'\n","      # f'WEIGHT_DECAY = {WEIGHT_DECAY}\\n'\n","      f'BATCH_SIZE = {BATCH_SIZE}')\n","main(pretrained_model=PRETRAINED_MODEL,\n","      epochs=EPOCHS,\n","      weight_decay=WEIGHT_DECAY,\n","      batch_size=BATCH_SIZE,\n","      lr=LR,\n","      optimizer=OPTIMIZER,\n","      eval_on_test=EVAL_ON_TEST)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nyzMIVqo4PVh","executionInfo":{"status":"ok","timestamp":1700601234124,"user_tz":480,"elapsed":1561992,"user":{"displayName":"Deepayan Sur","userId":"07020037218435868611"}},"outputId":"f5c9d4a6-98e2-4555-b28e-4695f94692e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PRETRAINED_MODEL = None\n","EPOCHS = 40\n","HIDDEN_DIM = 400\n","EMBEDDING_DIM = 400\n","NUM_LSTM_LAYERS = 1\n","OPTIMIZER = adam\n","BATCH_SIZE = 64\n","2407\n","2410\n","Training model\n","Running for 40 epochs\n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 1: 0.26814 and training accuracy: 0.8869\n","Training Accuracy: 0.8868783712387085 0\n","Training Loss: 0.2681361338273235 0\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.19690, accuracy: 0.9210, \n","Dev Accuracy: 0.9209907650947571 0\n","Dev Loss: 0.19689608715988438 0\n","Time spent in epoch 1: 41.02 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 2: 0.14857 and training accuracy: 0.9274\n","Training Accuracy: 0.9273706674575806 1\n","Training Loss: 0.14857154116068497 1\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.18114, accuracy: 0.9338, \n","Dev Accuracy: 0.9338282346725464 1\n","Dev Loss: 0.18113667231277916 1\n","Time spent in epoch 2: 39.07 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 3: 0.10385 and training accuracy: 0.9460\n","Training Accuracy: 0.9459683895111084 2\n","Training Loss: 0.10384886102907251 2\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.13872, accuracy: 0.9460, \n","Dev Accuracy: 0.9460287094116211 2\n","Dev Loss: 0.13872089947670185 2\n","Time spent in epoch 3: 38.28 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 4: 0.07722 and training accuracy: 0.9569\n","Training Accuracy: 0.9568653106689453 3\n","Training Loss: 0.07721993999163124 3\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.14043, accuracy: 0.9500, \n","Dev Accuracy: 0.9500465393066406 3\n","Dev Loss: 0.14042948972843267 3\n","Time spent in epoch 4: 38.19 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 5: 0.05638 and training accuracy: 0.9665\n","Training Accuracy: 0.9664787650108337 4\n","Training Loss: 0.05637920275574846 4\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.12728, accuracy: 0.9550, \n","Dev Accuracy: 0.9550198316574097 4\n","Dev Loss: 0.12728457651181338 4\n","Time spent in epoch 5: 41.57 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 6: 0.04291 and training accuracy: 0.9729\n","Training Accuracy: 0.9729212522506714 5\n","Training Loss: 0.04290902043499875 5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.14746, accuracy: 0.9520, \n","Dev Accuracy: 0.9520309567451477 5\n","Dev Loss: 0.14745741127829615 5\n","Time spent in epoch 6: 39.11 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 7: 0.03248 and training accuracy: 0.9787\n","Training Accuracy: 0.9786843061447144 6\n","Training Loss: 0.032481512850031286 6\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.14549, accuracy: 0.9559, \n","Dev Accuracy: 0.9558773040771484 6\n","Dev Loss: 0.14548686513153997 6\n","Time spent in epoch 7: 40.71 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 8: 0.02350 and training accuracy: 0.9846\n","Training Accuracy: 0.9846234917640686 7\n","Training Loss: 0.023503388127674905 7\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.14297, accuracy: 0.9574, \n","Dev Accuracy: 0.9574207663536072 7\n","Dev Loss: 0.14297331464587276 7\n","Time spent in epoch 8: 38.66 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 9: 0.01888 and training accuracy: 0.9874\n","Training Accuracy: 0.9873666167259216 8\n","Training Loss: 0.018879235642865765 8\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.14282, accuracy: 0.9584, \n","Dev Accuracy: 0.9584252238273621 8\n","Dev Loss: 0.14281896498157887 8\n","Time spent in epoch 9: 39.47 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 10: 0.01464 and training accuracy: 0.9901\n","Training Accuracy: 0.9901348948478699 9\n","Training Loss: 0.01464115990005746 9\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.16376, accuracy: 0.9587, \n","Dev Accuracy: 0.9586701989173889 9\n","Dev Loss: 0.16376011730380982 9\n","Time spent in epoch 10: 38.15 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 11: 0.01162 and training accuracy: 0.9923\n","Training Accuracy: 0.9922739863395691 10\n","Training Loss: 0.011624133456904138 10\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.15486, accuracy: 0.9593, \n","Dev Accuracy: 0.9593316912651062 10\n","Dev Loss: 0.1548580504575386 10\n","Time spent in epoch 11: 37.40 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 12: 0.01093 and training accuracy: 0.9925\n","Training Accuracy: 0.9924501776695251 11\n","Training Loss: 0.010927697483672809 11\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.16615, accuracy: 0.9587, \n","Dev Accuracy: 0.9586946964263916 11\n","Dev Loss: 0.16615185393647436 11\n","Time spent in epoch 12: 37.39 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 13: 0.00925 and training accuracy: 0.9936\n","Training Accuracy: 0.9935826659202576 12\n","Training Loss: 0.00924854461701103 12\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.15911, accuracy: 0.9597, \n","Dev Accuracy: 0.9596991539001465 12\n","Dev Loss: 0.1591132279933845 12\n","Time spent in epoch 13: 38.49 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 14: 0.00761 and training accuracy: 0.9952\n","Training Accuracy: 0.9952184557914734 13\n","Training Loss: 0.007606346231007785 13\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.17949, accuracy: 0.9589, \n","Dev Accuracy: 0.9588661789894104 13\n","Dev Loss: 0.17948864429018252 13\n","Time spent in epoch 14: 38.45 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 15: 0.00562 and training accuracy: 0.9958\n","Training Accuracy: 0.9958224296569824 14\n","Training Loss: 0.005616552164286303 14\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.18130, accuracy: 0.9596, \n","Dev Accuracy: 0.9596011638641357 14\n","Dev Loss: 0.18130057490884455 14\n","Time spent in epoch 15: 39.66 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 16: 0.00600 and training accuracy: 0.9961\n","Training Accuracy: 0.9960992336273193 15\n","Training Loss: 0.00600211662569678 15\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.18517, accuracy: 0.9596, \n","Dev Accuracy: 0.9596011638641357 15\n","Dev Loss: 0.18516780343113604 15\n","Time spent in epoch 16: 37.53 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 17: 0.00675 and training accuracy: 0.9960\n","Training Accuracy: 0.9960237741470337 16\n","Training Loss: 0.006754803094689532 16\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.20651, accuracy: 0.9585, \n","Dev Accuracy: 0.9585477113723755 16\n","Dev Loss: 0.20651390132299985 16\n","Time spent in epoch 17: 37.74 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 18: 0.00720 and training accuracy: 0.9962\n","Training Accuracy: 0.9961747527122498 17\n","Training Loss: 0.007200702734367149 17\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.17962, accuracy: 0.9573, \n","Dev Accuracy: 0.9572737812995911 17\n","Dev Loss: 0.179618733940628 17\n","Time spent in epoch 18: 38.74 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 19: 0.00518 and training accuracy: 0.9967\n","Training Accuracy: 0.9966780543327332 18\n","Training Loss: 0.005182793647229756 18\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.19021, accuracy: 0.9600, \n","Dev Accuracy: 0.9600176215171814 18\n","Dev Loss: 0.19020773456834905 18\n","Time spent in epoch 19: 38.71 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 20: 0.00425 and training accuracy: 0.9979\n","Training Accuracy: 0.9978609085083008 19\n","Training Loss: 0.0042486061965305915 19\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.20833, accuracy: 0.9594, \n","Dev Accuracy: 0.9593806862831116 19\n","Dev Loss: 0.20833266678327897 19\n","Time spent in epoch 20: 40.46 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 21: 0.00384 and training accuracy: 0.9977\n","Training Accuracy: 0.9977098703384399 20\n","Training Loss: 0.0038379057335276704 20\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.19349, accuracy: 0.9608, \n","Dev Accuracy: 0.9608016014099121 20\n","Dev Loss: 0.19349479124136945 20\n","Time spent in epoch 21: 38.00 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 22: 0.00509 and training accuracy: 0.9969\n","Training Accuracy: 0.9968793988227844 21\n","Training Loss: 0.005093245197873416 21\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.21929, accuracy: 0.9590, \n","Dev Accuracy: 0.9589641690254211 21\n","Dev Loss: 0.21928636870033286 21\n","Time spent in epoch 22: 37.43 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 23: 0.00590 and training accuracy: 0.9964\n","Training Accuracy: 0.9964264035224915 22\n","Training Loss: 0.0058975884114703435 22\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.20128, accuracy: 0.9600, \n","Dev Accuracy: 0.959968626499176 22\n","Dev Loss: 0.20127545367209787 22\n","Time spent in epoch 23: 42.03 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 24: 0.00464 and training accuracy: 0.9972\n","Training Accuracy: 0.9972317218780518 23\n","Training Loss: 0.004642329702111192 23\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.20427, accuracy: 0.9594, \n","Dev Accuracy: 0.9593806862831116 23\n","Dev Loss: 0.2042656914070774 23\n","Time spent in epoch 24: 38.00 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 25: 0.00418 and training accuracy: 0.9975\n","Training Accuracy: 0.9975085854530334 24\n","Training Loss: 0.004183155542052961 24\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.20633, accuracy: 0.9598, \n","Dev Accuracy: 0.9597971439361572 24\n","Dev Loss: 0.20632749444634477 24\n","Time spent in epoch 25: 37.54 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 26: 0.00326 and training accuracy: 0.9977\n","Training Accuracy: 0.9976847171783447 25\n","Training Loss: 0.003260267029035725 25\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.20495, accuracy: 0.9605, \n","Dev Accuracy: 0.9604831337928772 25\n","Dev Loss: 0.20495412346915434 25\n","Time spent in epoch 26: 37.71 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 27: 0.00360 and training accuracy: 0.9976\n","Training Accuracy: 0.9976091980934143 26\n","Training Loss: 0.003602303535762902 26\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.20643, accuracy: 0.9610, \n","Dev Accuracy: 0.961046576499939 26\n","Dev Loss: 0.20642525400992365 26\n","Time spent in epoch 27: 38.69 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 28: 0.00271 and training accuracy: 0.9985\n","Training Accuracy: 0.9985151886940002 27\n","Training Loss: 0.0027094382624070525 27\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.22133, accuracy: 0.9603, \n","Dev Accuracy: 0.960262656211853 27\n","Dev Loss: 0.22132581793599046 27\n","Time spent in epoch 28: 38.75 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 29: 0.00241 and training accuracy: 0.9985\n","Training Accuracy: 0.9984648823738098 28\n","Training Loss: 0.002411747381166443 28\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.22642, accuracy: 0.9610, \n","Dev Accuracy: 0.961046576499939 28\n","Dev Loss: 0.22642001780983728 28\n","Time spent in epoch 29: 37.76 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 30: 0.00231 and training accuracy: 0.9986\n","Training Accuracy: 0.9986410140991211 29\n","Training Loss: 0.0023129916697737876 29\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.21645, accuracy: 0.9611, \n","Dev Accuracy: 0.9610710740089417 29\n","Dev Loss: 0.21644891339738914 29\n","Time spent in epoch 30: 37.55 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 31: 0.00234 and training accuracy: 0.9987\n","Training Accuracy: 0.9987165331840515 30\n","Training Loss: 0.0023417373568662262 30\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.23248, accuracy: 0.9597, \n","Dev Accuracy: 0.9596746563911438 30\n","Dev Loss: 0.2324827830513745 30\n","Time spent in epoch 31: 40.06 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 32: 0.00280 and training accuracy: 0.9983\n","Training Accuracy: 0.9982886910438538 31\n","Training Loss: 0.0027950238885374136 31\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.22328, accuracy: 0.9606, \n","Dev Accuracy: 0.9605811238288879 31\n","Dev Loss: 0.22327746864505968 31\n","Time spent in epoch 32: 37.85 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 33: 0.00211 and training accuracy: 0.9986\n","Training Accuracy: 0.9985907077789307 32\n","Training Loss: 0.0021127051144654357 32\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.23712, accuracy: 0.9597, \n","Dev Accuracy: 0.9597236514091492 32\n","Dev Loss: 0.23712132496667415 32\n","Time spent in epoch 33: 38.73 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 34: 0.00277 and training accuracy: 0.9986\n","Training Accuracy: 0.9985907077789307 33\n","Training Loss: 0.002766955403370486 33\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.24378, accuracy: 0.9594, \n","Dev Accuracy: 0.9593806862831116 33\n","Dev Loss: 0.24378451453242042 33\n","Time spent in epoch 34: 38.48 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 35: 0.00332 and training accuracy: 0.9978\n","Training Accuracy: 0.9978356957435608 34\n","Training Loss: 0.003322427758413709 34\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.24715, accuracy: 0.9598, \n","Dev Accuracy: 0.9597971439361572 34\n","Dev Loss: 0.24714950973164193 34\n","Time spent in epoch 35: 37.46 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 36: 0.00307 and training accuracy: 0.9983\n","Training Accuracy: 0.9982635378837585 35\n","Training Loss: 0.003069599527230924 35\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.23473, accuracy: 0.9602, \n","Dev Accuracy: 0.9602381587028503 35\n","Dev Loss: 0.23472933080379196 35\n","Time spent in epoch 36: 39.55 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 37: 0.00254 and training accuracy: 0.9986\n","Training Accuracy: 0.9986410140991211 36\n","Training Loss: 0.002542318653661918 36\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.24837, accuracy: 0.9607, \n","Dev Accuracy: 0.9607036113739014 36\n","Dev Loss: 0.24836818388802182 36\n","Time spent in epoch 37: 37.60 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 38: 0.00345 and training accuracy: 0.9980\n","Training Accuracy: 0.9979615211486816 37\n","Training Loss: 0.00344644989251697 37\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.23481, accuracy: 0.9600, \n","Dev Accuracy: 0.9599931240081787 37\n","Dev Loss: 0.23480577129627386 37\n","Time spent in epoch 38: 38.17 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 39: 0.00504 and training accuracy: 0.9977\n","Training Accuracy: 0.9977350234985352 38\n","Training Loss: 0.005041960870259204 38\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.24214, accuracy: 0.9597, \n","Dev Accuracy: 0.9596991539001465 38\n","Dev Loss: 0.24213970284760197 38\n","Time spent in epoch 39: 41.33 \n","64\n","2407\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average training error in epoch 40: 0.00304 and training accuracy: 0.9983\n","Training Accuracy: 0.9982635378837585 39\n","Training Loss: 0.0030395434670973842 39\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\n","Average total loss dev: 0.24040, accuracy: 0.9614, \n","Dev Accuracy: 0.9613651037216187 39\n","Dev Loss: 0.24039900596630795 39\n","Time spent in epoch 40: 37.77 \n","\n","Best dev accuracy: 0.9613651037216187 found in EPOCH: 39\n","Testing model\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Saving model\n","Saving predictions\n"]}]},{"cell_type":"markdown","source":["### LanguageIdentifier.py     # class for language identifier"],"metadata":{"id":"XiiyIPFe4e8Q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cE5N0PjA3yf0"},"outputs":[],"source":["from torchtext.data import sentencepiece_numericalizer, load_sp_model, sentencepiece_tokenizer\n","\n","# from lstm_model import LSTMLIDModel # lstm_model.py\n","from nltk import TreebankWordTokenizer\n","import torch\n","from pathlib import Path\n","\n","\n","class LanguageIdentifier:\n","    \"\"\"\n","    Word-level language identifier\n","    \"\"\"\n","    def __init__(self, directory_path: Path = \"/content/drive/MyDrive/NLP_Project/trained_LID_model.pth\"):\n","        model_information_dict = torch.load(directory_path)\n","        subword_to_idx = sentencepiece_numericalizer(load_sp_model('/content/spm_user.model'))\n","        # lang_to_idx = {'bn': 0, 'en': 1, 'univ': 2, 'ne': 3, 'hi': 4, 'acro': 5, 'mixed': 6, 'undef': 7}\n","        lang_to_idx = {'lang1':0 , 'lang2': 1}\n","        self.model = LSTMLIDModel(subword_to_idx, lang_to_idx,\n","                                  model_information_dict['embedding_dim'],\n","                                  model_information_dict['hidden_dim'],\n","                                  model_information_dict['layers'])\n","        self.model.load_state_dict(model_information_dict['model_state_dict'], strict=False)\n","        self.tokenizer = TreebankWordTokenizer()\n","\n","    def tokenize(self, input_sentence: str) -> list[str]:\n","        return self.tokenizer.tokenize(input_sentence)\n","\n","    def predict(self, input_sentence: str) -> list[tuple[str, str]]:\n","        tokens = self.tokenize(input_sentence)\n","        return self.model.predict(tokens)\n","\n","    def rank(self, input_sentence: str) -> dict[str, list]:\n","        tokens = self.tokenize(input_sentence)\n","        return self.model.rank(tokens)\n","\n","\n","# To instantiate an instance of the language identifier\n","LID = LanguageIdentifier()\n","ex_sent = \"copy aur books bag main daalo\"\n","print(LID.predict(ex_sent))"]}]}