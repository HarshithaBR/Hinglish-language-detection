{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "JQtPoSX6Xusb"
      },
      "id": "JQtPoSX6Xusb"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsNjJQQlfMIb",
        "outputId": "9d284b46-c166-4d86-d6f0-85edaca181f0"
      },
      "id": "hsNjJQQlfMIb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr2_i7_LVp1k",
        "outputId": "d27bebf2-3fa4-451e-8570-7e2a264efd71"
      },
      "id": "Kr2_i7_LVp1k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199770 sha256=df00187e149d3cf68d64482a9f9d1372a3fe4c7202dedea12810edb91a94413f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e8a5dd5",
      "metadata": {
        "id": "1e8a5dd5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "# from typing_extensions import TypeAliasType\n",
        "\n",
        "try:\n",
        "    sys.path.append(os.path.join(os.path.dirname(__file__), '../'))\n",
        "except:\n",
        "    sys.path.append(os.path.join(os.getcwd(), '../'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from collections import Counter\n",
        "from sklearn import feature_extraction\n",
        "import random\n",
        "from itertools import product"
      ],
      "metadata": {
        "id": "sa3fpJmZPPjT"
      },
      "id": "sa3fpJmZPPjT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOFu8to-PW6-",
        "outputId": "50521992-5ac3-4e3c-b4b6-ab8ddbbdc1b3"
      },
      "id": "pOFu8to-PW6-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87837cfd",
      "metadata": {
        "id": "87837cfd",
        "outputId": "7d7ff67d-5132-4476-f645-def191000607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e22639b7f30>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import copy\n",
        "\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "import fasttext\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "CrjTXjQUYW8L"
      },
      "id": "CrjTXjQUYW8L"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28b18501",
      "metadata": {
        "id": "28b18501"
      },
      "outputs": [],
      "source": [
        "# train_file = '/content/drive/MyDrive/NLP_Project/IIITH_Codemixed.txt'\n",
        "train_file = '/content/drive/MyDrive/nlp_project/HIT-ACL2021-Codemixed-Representation/data/hindi_sentiment/IIITH_Codemixed.txt'\n",
        "df = pd.read_csv(train_file, sep='\\t', header=None, usecols=[1,2])\n",
        "df.columns = ['text', 'category']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering for Additional Features\n",
        "ie Feature Network"
      ],
      "metadata": {
        "id": "iPqBwASXYdFc"
      },
      "id": "iPqBwASXYdFc"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "with open(train_file, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "      parts = line.strip().split('\\t')\n",
        "      if len(parts) > 0:\n",
        "            sentences.append(parts[1])"
      ],
      "metadata": {
        "id": "XYl3QXdpopqj"
      },
      "id": "XYl3QXdpopqj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capital_words_count = []\n",
        "for sentence in sentences:\n",
        "    capital_words = re.findall(r'\\b[A-Z]+\\b', sentence)\n",
        "    capital_words_count.append(len(capital_words))"
      ],
      "metadata": {
        "id": "e2XQYd6vpL9c"
      },
      "id": "e2XQYd6vpL9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extended_words_count = []\n",
        "for sentence in sentences:\n",
        "    extended_words = re.findall(r'\\b\\w*([a-zA-Z])\\1\\w*\\b', sentence)\n",
        "    # print(extended_words)\n",
        "    extended_words_count.append(len(extended_words))"
      ],
      "metadata": {
        "id": "OAHVqybMpL51"
      },
      "id": "OAHVqybMpL51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exclamation_at_end = []\n",
        "for sentence in sentences:\n",
        "    exclamation_at_end.append(int(sentence.endswith('!')))"
      ],
      "metadata": {
        "id": "R9Lepsy3pL2a"
      },
      "id": "R9Lepsy3pL2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repeated_punctuation_count = []\n",
        "\n",
        "punctuation_pattern = r'(\\W)\\1+'\n",
        "\n",
        "for sentence in sentences:\n",
        "    repeated_punctuation = re.findall(punctuation_pattern, sentence)\n",
        "    repeated_punctuation_count.append(len(repeated_punctuation))\n",
        "\n",
        "print(repeated_punctuation_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFs50q_TpLy6",
        "outputId": "5833f0e9-5c77-4b34-f2bc-f11c2663896f"
      },
      "id": "NFs50q_TpLy6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 1, 1, 0, 5, 0, 0, 0, 0, 0, 1, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 4, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 7, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 2, 0, 2, 2, 0, 0, 4, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 9, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 2, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 36, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 4, 0, 0, 0, 0, 0, 2, 0, 0, 7, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 3, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 2, 0, 1, 4, 2, 0, 92, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 1, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 0, 1, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 10, 0, 1, 0, 0, 0, 1, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 3, 0, 2, 0, 0, 0, 0, 9, 0, 8, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 3, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 4, 5, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 6, 2, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 1, 1, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 6, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 1, 1, 4, 0, 1, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 1, 3, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 3, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 2, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 2, 1, 4, 0, 0, 2, 0, 0, 0, 3, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 3, 0, 1, 0, 2, 1, 0, 1, 2, 1, 2, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 3, 0, 1, 0, 0, 0, 0, 0, 1, 3, 0, 2, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1, 0, 2, 1, 3, 1, 0, 0, 2, 1, 2, 0, 0, 0, 3, 1, 0, 9, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 4, 0, 2, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 1, 6, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 3, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 6, 0, 0, 4, 7, 1, 0, 1, 0, 0, 3, 1, 4, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 2, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 1, 3, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 0, 1, 0, 1, 0, 2, 0, 0, 3, 0, 1, 0, 0, 0, 6, 2, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 4, 0, 0, 3, 0, 0, 0, 0, 3, 0, 2, 1, 0, 2, 0, 2, 2, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 3, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 3, 1, 0, 1, 0, 1, 0, 3, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 3, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_scores(word_list):\n",
        "    sentiment_scores_pos = sentiment_scores_neg = 0\n",
        "    for word in word_list:\n",
        "        synsets = list(swn.senti_synsets(word))\n",
        "        if synsets:\n",
        "            pos_score = synsets[0].pos_score()\n",
        "            neg_score = synsets[0].neg_score()\n",
        "            sentiment_scores_pos += pos_score\n",
        "            sentiment_scores_neg += neg_score\n",
        "    return sentiment_scores_pos,sentiment_scores_neg"
      ],
      "metadata": {
        "id": "Q7XR0LKMpLrm"
      },
      "id": "Q7XR0LKMpLrm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_sentiment_score = []\n",
        "neg_sentiment_score = []\n",
        "\n",
        "punctuation_pattern = r'(\\W)\\1+'\n",
        "\n",
        "for sentence in sentences:\n",
        "    pos_sentiment,negetive_sentiment = get_sentiment_scores(sentence.split(' '))\n",
        "    # print(pos_sentiment)\n",
        "    pos_sentiment_score.append((pos_sentiment))\n",
        "    neg_sentiment_score.append((negetive_sentiment))\n",
        "\n",
        "\n",
        "print(pos_sentiment_score)\n",
        "print(neg_sentiment_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGmKvuKjpqQg",
        "outputId": "ff11a95c-4122-49d9-87a5-3d807f6bc835"
      },
      "id": "MGmKvuKjpqQg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 1.375, 0.0, 0, 0.0, 0, 1.0, 1.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.375, 0.5, 1.375, 0.0, 0.375, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.75, 0.625, 0.75, 0.5, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0, 0.25, 0.375, 0.0, 0.0, 0.5, 0.0, 0.0, 0.75, 0.0, 0.625, 0.0, 0.5, 0.0, 0.0, 0.25, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0, 0.25, 0.5, 0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.5, 0, 0.625, 0, 0.25, 0.75, 1.125, 0, 1.125, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.5, 0.25, 0.875, 0.375, 1.0, 0.0, 0.5, 0.0, 0.5, 0.875, 0.0, 0.0, 0.0, 1.125, 0.0, 0.0, 0.25, 0.0, 0.25, 0.5, 1.0, 0.0, 0.0, 0.625, 0.0, 0.375, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0.0, 0, 0.0, 0.375, 0.5, 0.5, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.875, 0.375, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.25, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.75, 0.0, 0.375, 0.0, 0.0, 0.125, 0.0, 1.25, 0.25, 0.0, 1.625, 0.25, 0.0, 0.0, 0.0, 0.625, 0.25, 0.5, 0.0, 1.125, 0.0, 0.25, 0.5, 0.375, 0.0, 0.25, 0.0, 0.0, 0.5, 0.0, 0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.5, 0.25, 0.0, 0.375, 0.0, 0.25, 0.0, 0, 0.25, 0.0, 0.625, 0.875, 0.0, 0.0, 0.0, 0.875, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.5, 0.0, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0, 0.375, 0.0, 0.25, 0.25, 0.25, 0.0, 0.0, 0.625, 0, 0.0, 0.25, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.25, 0.25, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 1.125, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.458, 0, 0.375, 0.25, 0.0, 0.25, 0.75, 0.0, 0.375, 0.0, 0.25, 0.25, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.25, 0.25, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.5, 0.375, 0.625, 0, 0.25, 0.25, 0.0, 0.375, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.375, 1.125, 0.0, 0.0, 0.125, 0.0, 0.0, 1.125, 0.0, 0.0, 0.625, 0.75, 0.0, 0, 0.0, 0.0, 0.25, 0.25, 0.25, 0.25, 0.25, 0, 0.5, 0.0, 0.0, 0.75, 0.25, 0.0, 0.0, 0.125, 0.5, 0.25, 0.0, 0.375, 0, 0.5, 0.25, 0.0, 0.0, 0.25, 0.25, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.375, 0.75, 0.25, 0.25, 0.0, 0.25, 0.375, 0.0, 0.25, 0.25, 0.0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.875, 0.0, 0.0, 0.0, 0.125, 0, 0.0, 0.0, 0.875, 0.0, 0.0, 0.25, 0.125, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.875, 0.0, 0.0, 0.625, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.875, 0, 0.25, 0, 0.125, 0.0, 0.0, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0, 0.5, 0.0, 0.0, 3.75, 0.0, 0.25, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.5, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.0, 0.0, 0.0, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.5, 0.0, 0.0, 0.0, 0.0, 0.25, 0, 0.0, 0.625, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.375, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0, 0.375, 0.625, 0.0, 0.0, 0.0, 0, 0.875, 0.0, 0.25, 0.0, 0.0, 0, 0, 0.0, 0.0, 0, 0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.625, 0.25, 0.0, 0.0, 0.25, 0.5, 0.875, 0.0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.125, 0.125, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.125, 0.0, 0.125, 0.25, 0.25, 0.0, 0.25, 0.875, 0.0, 0.5, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.75, 0.0, 0.0, 0.5, 0.875, 0.875, 0.0, 0.25, 0.0, 0.0, 1.375, 0.0, 0.125, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.125, 0.0, 0.0, 0.0, 1.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0, 0.125, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 1.5, 0.0, 0.0, 0.0, 0.75, 0.0, 0.25, 0.25, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 1.0, 1.875, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.625, 0.25, 0, 0.25, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.375, 0.25, 0.0, 0.0, 0.0, 0.125, 0.0, 0, 0.25, 0.0, 0.125, 0.625, 0.125, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25, 0.0, 0.375, 0.0, 0.375, 0.0, 0.375, 0.0, 0.625, 0.0, 0.25, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.625, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.25, 0.125, 0.375, 0.0, 0.625, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0.625, 0.25, 0.25, 0.0, 0.25, 0.25, 0.0, 0, 0.25, 0, 0, 0.5, 0.75, 0.25, 0.0, 0.0, 0, 0.375, 0.0, 0.25, 0, 0.5, 0.25, 0.0, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.25, 0.0, 0.0, 0.0, 2.5, 0.0, 0, 0.25, 0.125, 0.25, 0.5, 0.0, 0.5, 0.625, 0.125, 0.0, 0, 0.5, 0.0, 0.0, 0.75, 0.5, 0.0, 0.0, 0.0, 0.875, 0.5, 0.75, 0.25, 0.5, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.75, 0.125, 0, 1.125, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0, 0, 0.0, 0.375, 0.25, 0.5, 0.25, 0.25, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.5, 0, 0.375, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.0, 0.375, 0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.5, 0.25, 0.0, 1.5, 0.75, 0.0, 0.25, 0.0, 3.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 0, 0.0, 0.0, 0.0, 1.25, 0.0, 0.0, 0.0, 0.25, 0, 0.0, 0.75, 0.25, 0.0, 0.0, 0.25, 0, 0.25, 0.0, 0.0, 0.0, 0.5, 0.25, 0.0, 0.0, 0.25, 0, 0.0, 0.0, 0.75, 0.0, 0.0, 0, 0.625, 0.125, 0.125, 0.25, 0.0, 0.0, 0.0, 0.625, 0.0, 0.625, 0.0, 0.125, 0.625, 0.625, 0.0, 0.25, 0.625, 0.625, 0.5, 0.25, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0, 1.0, 0.125, 0.0, 0.75, 0.5, 0.0, 0.0, 0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.25, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25, 0.375, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0, 0.25, 0.625, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 0.75, 0.75, 0.0, 0.25, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.875, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.5, 0.125, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.25, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.875, 0.125, 0.75, 0.0, 0.125, 0.25, 0.0, 0, 0.0, 0, 1.25, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 1.875, 0, 2.0, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 1.25, 0.5, 0.0, 0.0, 0.375, 0.0, 0.25, 0, 1.125, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0.875, 0.625, 0.25, 0, 0, 0.25, 0, 0.625, 0.125, 0.0, 0, 0.0, 0.75, 0.0, 0, 1.375, 0.0, 0.5, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.0, 0.125, 0, 0.0, 0.0, 0.5, 0.25, 0.25, 0.5, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.125, 0.125, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.625, 0, 0.25, 0.0, 0, 0.0, 0.5, 0.0, 2.25, 0.875, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 1.375, 0.25, 0.875, 0.375, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.125, 0.0, 0.25, 0.125, 0, 0.5, 0, 0.0, 0.625, 0.125, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 2.375, 0.0, 0.0, 1.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 1.125, 0.0, 0.0, 0.0, 0.0, 0.25, 0, 0.0, 0.25, 0.25, 0.25, 0.0, 0.0, 0.0, 0, 0.25, 0, 0.0, 0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.25, 0.25, 0.875, 0, 0.0, 0.25, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.875, 1.5, 0.875, 0.0, 0.0, 0.125, 0.5, 0.75, 0.5, 0.0, 0.0, 0, 3.125, 0.125, 0.0, 0, 0.0, 0, 0, 0.5, 0.0, 0.0, 0.0, 0.125, 0.5, 1.25, 0.0, 0.0, 0.875, 0.0, 0.0, 0.0, 2.5, 0.125, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0, 1.125, 0.0, 0.625, 0.125, 0.0, 0.25, 0.25, 1.0, 0.625, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.625, 0.0, 0.25, 0.0, 0.875, 0.25, 0.0, 0.625, 0.0, 0.25, 0.0, 0.0, 0.0, 0.875, 0.5, 0.25, 0.0, 0.0, 0.125, 0.125, 0.0, 0.875, 0.0, 0.5, 0.0, 0.0, 0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.625, 0.25, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.625, 0.0, 1.25, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0, 0.0, 0.0, 0.375, 0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 1.375, 0.0, 1.125, 0.25, 0.25, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.875, 0.0, 0, 0.5, 0.0, 0.625, 0.25, 0.0, 0.0, 0.25, 0.0, 0.25, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0, 0.625, 0, 0.0, 0.25, 0.125, 0.0, 0.0, 0.5, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.0, 0, 0.0, 0.5, 0.25, 0.0, 0.5, 0.5, 3.125, 0, 0.0, 0.0, 0.0, 1.25, 0.0, 0, 0.0, 1.0, 0, 0.5, 0.0, 0.5, 0.25, 0, 3.75, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.5, 0, 0.25, 0.125, 0.0, 0.125, 0.25, 0.25, 0.0, 0.25, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.125, 1.25, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.125, 0.0, 0.125, 0.25, 0.875, 0.0, 0.625, 0.0, 1.0, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.25, 0.875, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0, 0, 0.875, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.375, 0.125, 0.125, 0.0, 0.375, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.5, 0.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.875, 0.0, 0.5, 0.25, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.125, 0.25, 0.0, 0.25, 0.0, 0.5, 0.0, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.25, 0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.375, 0.0, 0.375, 0.125, 1.0, 0.0, 0.25, 0.25, 0.0, 0.375, 0.0, 0.875, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.25, 0, 0.0, 0.375, 0.375, 0.875, 0.0, 0.625, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.625, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.5, 0, 0, 0.25, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.375, 0.0, 0.0, 0, 0.0, 0.5, 0.25, 0.0, 0.0, 0, 0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.5, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.625, 0.0, 0.0, 0.5, 0.875, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 1.625, 0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 1.125, 0.0, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.25, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0, 0.0, 0.0, 0.0, 0.625, 0.5, 0.0, 0.0, 2.75, 0.0, 0, 0, 0.25, 0, 0, 0, 0.25, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 1.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.5, 0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.375, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.875, 0.25, 0.25, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0.0, 1.625, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.25, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.375, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.625, 0.625, 0.0, 0, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0, 0.0, 0.25, 0.625, 0.0, 0, 0.25, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0.0, 0.25, 0.0, 0.25, 0.0, 0.0, 0.25, 0, 0.0, 0.25, 0.25, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.875, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.75, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 1.25, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0, 0.0, 0, 0.5, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.375, 0.75, 0.25, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.25, 0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.5, 0.0, 0.0, 0.0, 0, 0.25, 0.875, 0.0, 0.875, 0.25, 0.0, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.0, 0.25, 0, 0, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.25, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.625, 0.5, 0.0, 0.25, 0.0, 0.25, 0.0, 0, 0.25, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0.375, 0.25, 0.625, 0.0, 1.125, 0.0, 0.0, 0.0, 0.0, 0, 0.5, 0.0, 0.0, 0.625, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.125, 0.25, 0.25, 0.625, 0, 0, 0.0, 0.125, 0.0, 0.0, 0.5, 0, 0.5, 0.0, 0.375, 0, 0.875, 0.0, 0.375, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.125, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 1.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.125, 0.0, 0.125, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.125, 0.125, 0.0, 0.0, 0.125, 0.5, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0, 0.0, 0.0, 1.0, 0.125, 1.625, 0.5, 0.125, 0.0, 0.375, 0.25, 0.0, 0.0, 0.25, 0.0, 0.75, 0.75, 0.0, 0.0, 0, 0.0, 0.5, 0, 0.0, 0.0, 1.125, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.25, 0.5, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 1.125, 0.375, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0, 0.375, 0.25, 0.0, 0.0, 0.125, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.5, 0, 0.0, 0.25, 0.0, 0.375, 0.0, 0.625, 0.25, 0.0, 0.0, 0.0, 0.0, 0.5, 0.25, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.25, 0.125, 0.25, 0.0, 0.0, 0, 0.0, 0.125, 0.0, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0, 0.625, 0.0, 0.125, 0.0, 0.0, 0.125, 0.0, 0.125, 0.0, 1.25, 0.0, 0.0, 0.125, 0.0, 0.375, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0, 0.25, 0.25, 0, 0.0, 0.0, 0.25, 0.375, 0.625, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.25, 0, 0.125, 0.0, 0.0, 0.0, 0.375, 0, 0.0, 0.5, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 2.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.75, 0.25, 0.125, 0.0, 0.0, 0.125, 0.0, 0.625, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0, 0.125, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.375, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.625, 0.0, 0.625, 0.25, 0.375, 0.125, 0.0, 0.25, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 0.0, 3.125, 0.0, 0.125, 0.0, 0.25, 0.75, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.75, 0.125, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.625, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.25, 0.375, 0.25, 0.0, 0.0, 0.0, 0.125, 0.5, 0, 2.375, 1.375, 0.0, 0.0, 0.0, 0.0, 0.375, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.125, 0.125, 0, 0.0, 0.0, 0.125, 0.0, 0.625, 0.0, 0.125, 0, 0.0, 0, 0.0, 0.125, 0.125, 0.0, 0, 0.0, 0.0, 0, 0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.375, 0.375, 0.0, 0.25, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0.125, 0.25, 0.0, 0.0, 0.0, 0.5, 0.0, 0.625, 0.25, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.0, 0.375, 0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.625, 0.0, 0.625, 0.0, 0.0, 0.0, 0.5, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.25, 0.0, 0.0, 0.0, 0.0, 0, 0.25, 0.375, 0.5, 0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0, 0.0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.625, 0.875, 0.25, 0.0, 0.0, 0.0, 0.25, 0.25, 0.0, 0.75, 0.0, 1.75, 0.625, 0.0, 0.0, 0, 0.0, 0.125, 0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.25, 0.375, 0.0, 0, 0.375, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1.875, 0.0, 0.0, 0.625, 0.625, 0.0, 0.0, 0.25, 0.0, 0.375, 0.25, 0.5, 0.0, 0.625, 0.0, 0.375, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.625, 0.875, 0.625, 0.625, 0, 0.0, 0.875, 0.0, 0.5, 0.5, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.5, 0.0, 0.125, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.625, 0.125, 0.0, 0.0, 0.25, 0.0, 0.75, 0.875, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.25, 0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.375, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.25, 0.875, 0, 0, 0.0, 0.625, 0.125, 0.0, 1.875, 0.25, 0.625, 0.625, 1.125, 0.0, 0, 0.0, 0.25, 1.0, 0, 0.0, 0.125, 0.0, 0.0, 1.0, 0.0, 0.0, 0.625, 0.25, 0.625, 0.75, 0, 0, 0, 0.0, 0.25, 0.0, 0.625, 0.125, 0.0, 0.25, 0.0, 0.5, 0.0, 0, 0.0, 0.0, 1.375, 0.125, 0.0, 0.25, 0, 0.0, 0.125, 0.875, 0.0, 0.0, 0.0, 0.0, 0.5, 0, 0.5, 0.625, 0.0, 0.125, 0.125, 0.0, 0.25, 0.25, 0.875, 0.625, 0.375, 0.5, 0, 0.25, 0.0, 0.0, 0.0, 0.75, 0.25, 0.625, 0.875, 0.0, 0.625, 0.5, 0.0, 0.0, 0.25, 0.25, 0.625, 0.0, 0.0, 0.0, 0.0, 1.0, 1.25, 0.25, 0.0, 0.0, 0.25, 0, 0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.875, 0.5, 0.125, 0.125, 0, 0.625, 0.0, 0.0, 0.0, 0, 0.0, 0, 0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.875, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0, 0.0, 0.125, 0.125, 0.0, 0.0, 0.0, 0.25, 0.625, 0.125, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.625, 0.0, 0.5, 0.0, 0, 0.5, 0.0, 0.25, 0.0, 0.0, 0.0, 0.5, 0.875, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.625, 0, 0.0, 0.0, 0, 0.125, 0, 0.375, 0.625, 0.0, 0.5, 0.0, 0.25, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0, 0.625, 0.375, 0.0, 0.375, 0.0, 0, 0.25, 1.0, 0.125, 0.0, 0, 0.25, 0, 0.5, 0, 0.125, 0.625, 0.0, 0.0, 0.625, 0.0, 0, 0.0, 0.625, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.25, 1.25, 1.25, 0.625, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.25, 0.0, 0, 0.875, 0.0, 0.125, 0.0, 0, 0.0, 0, 0.0, 0.125, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 1.25, 0.0, 0.0, 0.0, 0.0, 0.125, 0.875, 0.375, 0.0, 0.0, 0.0, 0.0, 0.125, 0.75, 0.0, 0.0, 0.25, 0.5, 0.5, 0.25, 0.0, 0.0, 0.0, 0.5, 0.0, 0.125, 0.0, 0.0, 0.25, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.25, 0.0, 0.375, 0.125, 0.0, 0.0, 0.5, 0.0, 0, 0.0, 0.125, 0.625, 0.75, 0, 1.125, 0.0, 0.75, 0.25, 0.5, 0, 0.0, 0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 0.375, 0.375, 0.0, 0.0, 0.875, 0.25, 0, 0.0, 0.0, 0.625, 0.0, 0.25, 0.0, 0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.375, 0, 0.125, 0.0, 0.875, 0.25, 0.625, 1.25, 0.0, 0.375, 0.25, 0.125, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 1.125, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.125, 0.25, 0.25, 0.875, 3.75, 0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.75, 0, 0, 0.25, 0.625, 0.0, 0.0, 0, 0.875, 0.25, 0.0, 0.625, 0, 0.0, 1.0, 0, 4.375, 0.5, 0.0, 0.625, 0.125, 0.0, 0.875, 0.0, 0.0, 0.25, 0.0, 1.125, 0.0, 0.0, 0.0, 0.0, 0.0, 1.25, 0.5, 0.5, 0.0, 0.0, 1.125, 2.75, 0.625, 0.25, 1.25, 0.0, 0.0, 0.25, 0.0, 0.5, 0.0, 0.25, 0, 0.0, 0.0, 0.0]\n",
            "[0.25, 0.125, 0.0, 0, 0.0, 0, 0.125, 0.625, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.75, 0.5, 0.625, 0.0, 0.0, 0, 0.0, 0.125, 0.0, 0.0, 0.0, 0, 0.0, 0.125, 0.0, 0.0, 0.5, 0.125, 0.0, 0.125, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.125, 0.0, 0.125, 0, 0.125, 0.375, 0.0, 0.0, 0.0, 0.875, 0.0, 0.125, 0.0, 0.25, 0.125, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0, 0.0, 0.0, 0, 0.0, 0.625, 0.0, 0.625, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.375, 0, 0.0, 0, 0.0, 1.0, 0.125, 0, 0.75, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.375, 0.0, 0.125, 0.5, 0.0, 0.5, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.375, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.625, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.125, 0.25, 0.0, 0.125, 0.0, 0.625, 0.125, 0.25, 0.0, 0.0, 0.25, 0.125, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.25, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.375, 0.125, 0.0, 0.0, 0.125, 0.0, 0.75, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0.0, 0.125, 0.25, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.125, 0.0, 0.875, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.5, 0.0, 0.25, 0.25, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.25, 1.292, 0, 0.125, 0.0, 0.0, 0.125, 0.25, 0.25, 0.0, 0.0, 1.25, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.5, 0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.75, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.875, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.25, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.5, 0.125, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.125, 0.625, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.25, 0.0, 0.75, 0, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.25, 0.25, 0.25, 0.0, 0.0, 0.0, 0.125, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.375, 0.75, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0.5, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0, 0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.125, 0.0, 0.0, 0.25, 0.0, 0.0, 0.625, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.25, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.125, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.625, 0.0, 0.0, 0.0, 0.125, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.25, 0.0, 0.5, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.25, 0.25, 0.25, 0.0, 0.0, 0.25, 0.125, 0.0, 0, 0.25, 0, 0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.75, 0.0, 0.125, 0.25, 0.5, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0.25, 0.0, 0, 1.0, 0.0, 0.25, 0.0, 0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.5, 0.25, 0, 0.125, 0.0, 0.0, 0.25, 0, 0.25, 0.0, 0.0, 0.0, 0.125, 0.75, 0.0, 0.375, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.375, 0.25, 0.0, 0.0, 0.0, 0.0, 0.125, 0.25, 0.5, 0.0, 0.375, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.875, 0.125, 0.125, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.375, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0, 0.0, 0.0, 0.625, 0.0, 0.125, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.5, 0.0, 0.0, 0, 0.125, 0.0, 0.0, 0.0, 0.375, 0.5, 0.0, 0.375, 0.0, 0.25, 0, 0.0, 0, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.125, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 1.125, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0.5, 0.0, 0.125, 0, 0, 0.0, 0, 0.75, 0.5, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.25, 0.25, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.375, 0.25, 0.0, 0.375, 0.0, 0.125, 0.5, 0.0, 0.0, 1.25, 0.0, 0.0, 0.0, 0.125, 0, 0.125, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 1.125, 0.0, 0.0, 0.625, 0.0, 0.0, 0.875, 0.0, 0.5, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.875, 0.875, 0.0, 0.0, 0, 0.125, 0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0, 0.0, 0.25, 0.5, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.25, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.25, 0.5, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0.875, 0.0, 0.0, 0.125, 0.0, 1.5, 0.0, 0.0, 0.0, 0, 0.125, 0.0, 0.25, 0.0, 0.25, 0.125, 0.375, 0.125, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.875, 0.125, 0.0, 0.0, 0.0, 0.125, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.75, 0.0, 0.125, 0.0, 0.0, 0.75, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.25, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0, 0.0, 0.0, 0.375, 0, 0.5, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.125, 0.625, 0.0, 0.875, 0.0, 0.0, 0.0, 0.0, 0, 0.5, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.5, 0.0, 0.125, 0.125, 0.5, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.375, 0.125, 0.25, 0.0, 0.125, 0.0, 0.625, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.25, 0.125, 0.625, 0.0, 0.125, 0.125, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0.125, 0.25, 0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.5, 0.75, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.25, 1.125, 0.0, 0.25, 0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.125, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.125, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.5, 0.75, 0.0, 0.0, 0.0, 0.0, 0.875, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.125, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 1.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.375, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.375, 0, 0, 0.0, 0.25, 0.0, 0.375, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.375, 0.0, 0, 0.0, 0.375, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.25, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.625, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.125, 0.0, 0.25, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.625, 0.0, 0, 0.0, 0, 0, 0.625, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.625, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.875, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0.25, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0.0, 0, 0, 0, 0.0, 1.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.375, 0.25, 0.0, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0, 0, 0.0, 1.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.375, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0, 0.25, 0, 0, 0.25, 0.25, 0.375, 0.25, 0, 0.0, 0.0, 0.25, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.875, 0, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.125, 0.0, 0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.625, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.25, 0.0, 0.125, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.25, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.25, 0.125, 0.25, 0.0, 0.0, 0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.375, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0, 0.125, 0.0, 0.0, 0.625, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 0.0, 0.0, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.125, 0.25, 0.0, 0.0, 0.25, 0.0, 1.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0, 0.625, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.375, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.75, 0.0, 0.0, 0.125, 0.25, 0.0, 0.0, 0.25, 0.0, 0.25, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.25, 0.25, 0.875, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.0, 0, 0.0, 0.75, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.5, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0, 0.375, 0.0, 0.0, 0.0, 0.25, 0.25, 0.25, 0.125, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.125, 0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.375, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.375, 0, 0.0, 0.375, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.125, 1.5, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.25, 0.0, 0.375, 0.0, 0.25, 0.375, 0.0, 0.0, 0.0, 0.25, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.125, 0.375, 0, 0.0, 0.0, 0.375, 0.0, 0.125, 0.0, 0.5, 0.0, 0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.75, 0.0, 0.0, 0.0, 0.5, 0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0.375, 0.0, 0.0, 0.0, 0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 1.25, 0.0, 0.0, 0, 0.0, 0.5, 0.625, 0.5, 0.0, 0.25, 0.25, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.75, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0, 0.0, 0.0, 0.0, 1.25, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.125, 0.0, 0.25, 0.0, 0.625, 0.0, 0.25, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.125, 0.0, 0.25, 0.0, 0, 0.125, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.125, 0.125, 0.0, 0.0, 0.0, 0.0, 0.125, 0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.5, 0.0, 0, 0.0, 0.0, 0.5, 0.25, 0.125, 0.0, 0.125, 0, 0.0, 0, 0.25, 0.5, 0.0, 0.0, 0, 0.0, 0.0, 0, 0, 0.0, 0.5, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.125, 0.0, 0.375, 0.0, 0.5, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.25, 0, 0, 0.5, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.25, 0.5, 0.0, 0.0, 0.25, 0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.75, 0.0, 0.625, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.625, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.25, 0, 0.25, 0.125, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.875, 0.0, 0, 0.0, 0.0, 0.25, 0.0, 1.125, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.125, 0.125, 0.125, 0.5, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.875, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.875, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.25, 0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.5, 0.0, 0.25, 0.0, 0.5, 0.25, 0.125, 0, 0, 0.0, 1.0, 0.125, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0, 0.5, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.375, 0.0, 0.0, 0.125, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0, 0.0, 0.0, 0.875, 0.75, 0.0, 0.0, 0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0.0, 1.625, 0.0, 0.0, 0.0, 0.0, 0.125, 0.5, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.0, 0.125, 0, 0, 0.0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.75, 0.125, 0, 0.0, 0.0, 0.0, 0.25, 0, 0.0, 0, 0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.125, 0.0, 0.25, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.25, 0, 0.25, 0.25, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.375, 0.375, 0.25, 0.125, 0.0, 0.0, 0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0, 0.625, 0.0, 0.875, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.125, 0.0, 0.0, 0.0, 0, 0.375, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.25, 0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.125, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0, 0.0, 0.0, 0.375, 0.0, 0, 0.0, 0, 0.0, 0.0, 0.125, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.25, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.125, 0.0, 0.25, 0.125, 0.0, 0, 0.0, 0, 0.0, 0.25, 0.125, 0.0, 0.125, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.25, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0, 0.625, 0.0, 0.375, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.125, 0, 0, 0.75, 0.0, 0.0, 0.0, 0, 0.0, 0.125, 0.0, 0.125, 0, 0.25, 0.0, 0, 0.625, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 0.0, 0.0, 0.125, 0.0, 0.0, 0.375, 0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Capital_Words_Count']= capital_words_count\n",
        "df['Extended_Words_Count']= extended_words_count\n",
        "df['Exclamation_at_End']= exclamation_at_end\n",
        "df['Repeated_Punctuation_Count']= repeated_punctuation_count\n",
        "df['Sentiment_Scores_positive']= pos_sentiment_score\n",
        "df['Sentiment_Scores_negetive']= neg_sentiment_score"
      ],
      "metadata": {
        "id": "K9RPza_-pqJQ"
      },
      "id": "K9RPza_-pqJQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "4fojrNHDpqCV",
        "outputId": "aa11ac8f-4df2-415c-9448-b70c956b6cc8"
      },
      "id": "4fojrNHDpqCV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  category  \\\n",
              "0  Ye song nahi hi Ye MODI Ji ka mehnat ka rang h...  Positive   \n",
              "1  Love u sir love u soo much urs I'ts beautyful ...  Positive   \n",
              "2  Arae sur jee pahelae hamare bharat ke bachho k...   Neutral   \n",
              "3  Wah! Jitni sundar geet ke bhao hain utnihi sun...  Positive   \n",
              "4  Sundar ekdam sahi Gaya Hua gana.chhotisi gudiy...  Positive   \n",
              "\n",
              "   Capital_Words_Count  Extended_Words_Count  Exclamation_at_End  \\\n",
              "0                    1                     0                   0   \n",
              "1                    1                     1                   0   \n",
              "2                    0                     4                   0   \n",
              "3                    0                     3                   0   \n",
              "4                    0                     1                   0   \n",
              "\n",
              "   Repeated_Punctuation_Count  Sentiment_Scores_positive  \\\n",
              "0                           1                      0.000   \n",
              "1                           1                      1.375   \n",
              "2                           1                      0.000   \n",
              "3                           0                      0.000   \n",
              "4                           0                      0.000   \n",
              "\n",
              "   Sentiment_Scores_negetive  \n",
              "0                      0.250  \n",
              "1                      0.125  \n",
              "2                      0.000  \n",
              "3                      0.000  \n",
              "4                      0.000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65b2fb35-02b0-47f2-a4db-ced7aced8e9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>Capital_Words_Count</th>\n",
              "      <th>Extended_Words_Count</th>\n",
              "      <th>Exclamation_at_End</th>\n",
              "      <th>Repeated_Punctuation_Count</th>\n",
              "      <th>Sentiment_Scores_positive</th>\n",
              "      <th>Sentiment_Scores_negetive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ye song nahi hi Ye MODI Ji ka mehnat ka rang h...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love u sir love u soo much urs I'ts beautyful ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.375</td>\n",
              "      <td>0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arae sur jee pahelae hamare bharat ke bachho k...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wah! Jitni sundar geet ke bhao hain utnihi sun...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sundar ekdam sahi Gaya Hua gana.chhotisi gudiy...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65b2fb35-02b0-47f2-a4db-ced7aced8e9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65b2fb35-02b0-47f2-a4db-ced7aced8e9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65b2fb35-02b0-47f2-a4db-ced7aced8e9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-68cd04d9-a1c9-46e0-bdfe-03cdb6c61c1b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68cd04d9-a1c9-46e0-bdfe-03cdb6c61c1b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-68cd04d9-a1c9-46e0-bdfe-03cdb6c61c1b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "7ajUeEn2YnfT"
      },
      "id": "7ajUeEn2YnfT"
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweets(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'@\\w+','',text)\n",
        "    text = re.sub(r'http\\w+','',text)\n",
        "    text = re.sub(r'#\\w+','',text)\n",
        "    text = re.sub(r'\\d+','',text)\n",
        "    text = text.strip()\n",
        "    # text = text.split(' ')\n",
        "    return text"
      ],
      "metadata": {
        "id": "fCJ7B4BijW1b"
      },
      "id": "fCJ7B4BijW1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.text = df.text.apply(lambda x: clean_tweets(x))\n",
        "\n",
        "print(df[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGAZuq5bja1A",
        "outputId": "559cad3d-a709-4738-e568-61b0450f6390"
      },
      "id": "HGAZuq5bja1A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  category  \\\n",
            "0  ye song nahi hi ye modi ji ka mehnat ka rang h...  Positive   \n",
            "1  love u sir love u soo much urs i'ts beautyful ...  Positive   \n",
            "2  arae sur jee pahelae hamare bharat ke bachho k...   Neutral   \n",
            "3  wah! jitni sundar geet ke bhao hain utnihi sun...  Positive   \n",
            "4  sundar ekdam sahi gaya hua gana.chhotisi gudiy...  Positive   \n",
            "\n",
            "   Capital_Words_Count  Extended_Words_Count  Exclamation_at_End  \\\n",
            "0                    1                     0                   0   \n",
            "1                    1                     1                   0   \n",
            "2                    0                     4                   0   \n",
            "3                    0                     3                   0   \n",
            "4                    0                     1                   0   \n",
            "\n",
            "   Repeated_Punctuation_Count  Sentiment_Scores_positive  \\\n",
            "0                           1                      0.000   \n",
            "1                           1                      1.375   \n",
            "2                           1                      0.000   \n",
            "3                           0                      0.000   \n",
            "4                           0                      0.000   \n",
            "\n",
            "   Sentiment_Scores_negetive  \n",
            "0                      0.250  \n",
            "1                      0.125  \n",
            "2                      0.000  \n",
            "3                      0.000  \n",
            "4                      0.000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "def add_vowel_noise(word):\n",
        "    vowels = 'a'\n",
        "    new_word = ''\n",
        "    for char in word:\n",
        "        new_word += char\n",
        "        if char in vowels:\n",
        "            new_word += random.choice(vowels)  # Add an extra vowel\n",
        "    return new_word\n",
        "\n",
        "def random_vowel_deletion(word):\n",
        "    # Delete a vowel\n",
        "    vowels = 'aeiou'\n",
        "    return ''.join(char for char in word if char not in vowels or (char in vowels))\n",
        "\n",
        "def ends_with(word):\n",
        "    possible_combinations = [word]\n",
        "    if len(word)>2:\n",
        "        if word.endswith('yu'):\n",
        "            possible_combinations.append(word + 'n')\n",
        "        if word.endswith('ha'):\n",
        "            possible_combinations.append(word + 'n')\n",
        "        if word.endswith('haa'):\n",
        "            possible_combinations.append(word + 'n')\n",
        "        if word.endswith('he'):\n",
        "            possible_combinations.append(word + 'y')\n",
        "        if word.endswith('ne'):\n",
        "            possible_combinations.append(word + 'y')\n",
        "        if word.endswith('he'):\n",
        "            possible_combinations.append(word + 'i')\n",
        "        if word.endswith('ne'):\n",
        "            possible_combinations.append(word + 'i')\n",
        "        if word.endswith('oo'):\n",
        "            possible_combinations.append(word[:-2] + 'u')\n",
        "        if word.endswith('ee'):\n",
        "            possible_combinations.append(word[:-2] + 'i')\n",
        "\n",
        "\n",
        "    if len(word)>1:\n",
        "        if word.endswith('u'):\n",
        "            possible_combinations.append(word[:-1] + 'oo')\n",
        "        if word.endswith('i'):\n",
        "            possible_combinations.append(word[:-1] + 'ee')\n",
        "\n",
        "    return possible_combinations\n",
        "\n",
        "def introduce_noise(words):\n",
        "    all_noise_words = []\n",
        "    mappings = {}\n",
        "\n",
        "    for word in tqdm(words):\n",
        "        noisy_combinations = ends_with(add_vowel_noise(random_vowel_deletion(word)))\n",
        "        all_noise_words.extend(noisy_combinations)\n",
        "        mappings[word] = noisy_combinations\n",
        "\n",
        "    all_noise_words = list(set(all_noise_words) - set(words))\n",
        "\n",
        "    return all_noise_words, mappings\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def extract_top_words(sentences, top_n=5000):\n",
        "    # Tokenize the sentences into words\n",
        "    words = ' '.join(sentences).split()\n",
        "\n",
        "    # Use Counter to count occurrences of each word\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    # Extract the top N occurring words\n",
        "    top_words = [word for word, _ in tqdm(word_counts.most_common(top_n))]\n",
        "\n",
        "    return top_words\n",
        "\n",
        "sentences = list(df.text)\n",
        "\n",
        "top_words = extract_top_words(sentences, top_n=5000)\n",
        "\n",
        "def replace_misspelled(sentences, mappings):\n",
        "    reversed_mappings = {value: key for key, values in mappings.items() for value in values}\n",
        "    replaced_sentences = []\n",
        "\n",
        "    for sentence in tqdm(sentences):\n",
        "        words = sentence.split()\n",
        "        corrected_words = [reversed_mappings.get(word, word) if word in reversed_mappings else word for word in words]\n",
        "        replaced_sentences.append(' '.join(corrected_words))\n",
        "\n",
        "    return replaced_sentences\n",
        "\n",
        "# sentences = list(train_df.text)\n",
        "\n",
        "def remove_starting_space_from_list(string_list):\n",
        "    return [string.lstrip() for string in string_list]\n",
        "\n",
        "def remove_end_space_from_list(string_list):\n",
        "    return [string.rstrip() for string in string_list]\n",
        "\n",
        "# Example usage\n",
        "sentences = remove_starting_space_from_list(sentences)\n",
        "sentences = remove_end_space_from_list(sentences)\n",
        "\n",
        "\n",
        "def percentage_difference(list1, list2):\n",
        "    common_strings = set(list1).intersection(set(list2))\n",
        "    total_strings = len(list1)\n",
        "    different_strings = total_strings - len(common_strings)\n",
        "    diff = list(set(list1) - common_strings)\n",
        "    percentage_diff = (different_strings / total_strings) * 100\n",
        "    return percentage_diff\n",
        "\n",
        "misspelled_words, wmappings = introduce_noise(top_words)\n",
        "\n",
        "# 'replaces sentences with list of sentences'\n",
        "# 'if you have list of tokens, then join to get sentence'\n",
        "\n",
        "# 'add sentences 2 to the df and tokenize again\n",
        "\n",
        "sentences2 = replace_misspelled(sentences, wmappings)\n",
        "p_result = percentage_difference(sentences, sentences2)\n",
        "df.text=sentences2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvtR0YqBjUCw",
        "outputId": "33bede00-510a-443d-ab72-795b1cf8fa54"
      },
      "id": "TvtR0YqBjUCw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:00<00:00, 1847711.01it/s]\n",
            "100%|██████████| 5000/5000 [00:00<00:00, 246078.17it/s]\n",
            "100%|██████████| 3879/3879 [00:00<00:00, 304687.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_unique(elems):\n",
        "    if type(elems[0]) == list:\n",
        "        corpus = flatten(elems)\n",
        "    else:\n",
        "        corpus = elems\n",
        "    elems, freqs = zip(*Counter(corpus).most_common())\n",
        "    return list(elems)\n",
        "\n",
        "\n",
        "def convert_categorical_label_to_int(labels):\n",
        "    if type(labels[0]) == list:\n",
        "        uniq_labels = _get_unique(flatten(labels))\n",
        "    else:\n",
        "        uniq_labels = _get_unique(labels)\n",
        "\n",
        "\n",
        "    if type(labels[0]) == list:\n",
        "        label_to_id = {w:i+1 for i,w in enumerate(uniq_labels)}\n",
        "    else:\n",
        "        label_to_id = {w:i for i,w in enumerate(uniq_labels)}\n",
        "\n",
        "    new_labels = []\n",
        "    if type(labels[0]) == list:\n",
        "        for i in labels:\n",
        "            new_labels.append([label_to_id[j] for j in i])\n",
        "    else:\n",
        "        new_labels = [label_to_id[j] for j in labels]\n",
        "\n",
        "    return new_labels, label_to_id"
      ],
      "metadata": {
        "id": "BP0adkUrkbdq"
      },
      "id": "BP0adkUrkbdq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.category, label2idx = convert_categorical_label_to_int(df.category.values)"
      ],
      "metadata": {
        "id": "9Uvba4g3kT0m"
      },
      "id": "9Uvba4g3kT0m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df, test_df = train_test_split(df, train_size=0.8, random_state=42)\n",
        "# train_df, val_df = train_test_split(train_df, train_size=0.9, random_state=42)"
      ],
      "metadata": {
        "id": "tN4z3zIhgPJp"
      },
      "id": "tN4z3zIhgPJp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for train_index, test_index in kf.split(df.text):\n",
        "    break\n",
        "\n",
        "test_df = df.iloc[test_index]\n",
        "kf2 = KFold(n_splits=8, shuffle=True, random_state=42)\n",
        "for train_index, val_index in kf2.split(df.iloc[train_index].text):\n",
        "    break\n",
        "\n",
        "val_df = df.iloc[val_index]\n",
        "train_df = df.iloc[train_index]"
      ],
      "metadata": {
        "id": "9eXcjaueN3Fn"
      },
      "id": "9eXcjaueN3Fn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f51c2e0",
      "metadata": {
        "id": "4f51c2e0",
        "outputId": "70c14cf3-3290-4964-e926-7b666606843b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2792 311 776\n"
          ]
        }
      ],
      "source": [
        "print(len(train_df['text']), len(val_df['text']), len(test_df['text']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "C9Kr2a8RdNhH",
        "outputId": "2c94a804-fac0-4cc1-88ff-95ae6a494730"
      },
      "id": "C9Kr2a8RdNhH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  category  \\\n",
              "1906  ek bat bta deta hoo ap sabko.... plz ijjat se ...   Neutral   \n",
              "391                               bharat \"modi\" ke sath  Positive   \n",
              "821   rfta rfta dakho akh mari kadi h akh jisa lgi m...  Positive   \n",
              "526                              kamal karte ho yr bhai   Neutral   \n",
              "2727                              ek reply bhai plzzzzz   Neutral   \n",
              "\n",
              "      Capital_Words_Count  Extended_Words_Count  Exclamation_at_End  \\\n",
              "1906                    1                     4                   0   \n",
              "391                     2                     1                   0   \n",
              "821                     0                     0                   0   \n",
              "526                     0                     0                   0   \n",
              "2727                    0                     1                   0   \n",
              "\n",
              "      Repeated_Punctuation_Count  Sentiment_Scores_positive  \\\n",
              "1906                           1                      0.000   \n",
              "391                            2                      0.000   \n",
              "821                            1                      0.625   \n",
              "526                            0                      0.000   \n",
              "2727                           1                      0.000   \n",
              "\n",
              "      Sentiment_Scores_negetive  \n",
              "1906                        0.0  \n",
              "391                         0.0  \n",
              "821                         0.5  \n",
              "526                         0.0  \n",
              "2727                        0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29097293-21d2-407c-b47f-2615a5376d3d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>Capital_Words_Count</th>\n",
              "      <th>Extended_Words_Count</th>\n",
              "      <th>Exclamation_at_End</th>\n",
              "      <th>Repeated_Punctuation_Count</th>\n",
              "      <th>Sentiment_Scores_positive</th>\n",
              "      <th>Sentiment_Scores_negetive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1906</th>\n",
              "      <td>ek bat bta deta hoo ap sabko.... plz ijjat se ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>bharat \"modi\" ke sath</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>821</th>\n",
              "      <td>rfta rfta dakho akh mari kadi h akh jisa lgi m...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>kamal karte ho yr bhai</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>ek reply bhai plzzzzz</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29097293-21d2-407c-b47f-2615a5376d3d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29097293-21d2-407c-b47f-2615a5376d3d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29097293-21d2-407c-b47f-2615a5376d3d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fc01f312-8dfe-4dc0-aaac-541a3e355d4b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc01f312-8dfe-4dc0-aaac-541a3e355d4b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fc01f312-8dfe-4dc0-aaac-541a3e355d4b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "ootyqFs0dPtm",
        "outputId": "2f1b806f-13fe-423c-accf-57b68fd2e46c"
      },
      "id": "ootyqFs0dPtm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  category  \\\n",
              "1826                         hiiiii, kya yeh dream hai?   Neutral   \n",
              "211   modi jee ap jesa koi nhi dhanywad ap desh ki k...  Positive   \n",
              "2861                           wtng for ur rply ....plz  Positive   \n",
              "410   bhai jo apno se dur ho toh unka toh yahi ek za...  Positive   \n",
              "1188                                      bhai jan nice  Positive   \n",
              "\n",
              "      Capital_Words_Count  Extended_Words_Count  Exclamation_at_End  \\\n",
              "1826                    0                     1                   0   \n",
              "211                     0                     3                   0   \n",
              "2861                    0                     0                   0   \n",
              "410                     0                     0                   0   \n",
              "1188                    0                     1                   0   \n",
              "\n",
              "      Repeated_Punctuation_Count  Sentiment_Scores_positive  \\\n",
              "1826                           0                      0.000   \n",
              "211                            0                      1.125   \n",
              "2861                           1                      0.000   \n",
              "410                            0                      0.000   \n",
              "1188                           0                      0.000   \n",
              "\n",
              "      Sentiment_Scores_negetive  \n",
              "1826                        0.0  \n",
              "211                         0.0  \n",
              "2861                        0.0  \n",
              "410                         0.0  \n",
              "1188                        0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c243c500-3907-488f-b7d8-dace5b307bd8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>Capital_Words_Count</th>\n",
              "      <th>Extended_Words_Count</th>\n",
              "      <th>Exclamation_at_End</th>\n",
              "      <th>Repeated_Punctuation_Count</th>\n",
              "      <th>Sentiment_Scores_positive</th>\n",
              "      <th>Sentiment_Scores_negetive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1826</th>\n",
              "      <td>hiiiii, kya yeh dream hai?</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>modi jee ap jesa koi nhi dhanywad ap desh ki k...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.125</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>wtng for ur rply ....plz</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>bhai jo apno se dur ho toh unka toh yahi ek za...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1188</th>\n",
              "      <td>bhai jan nice</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c243c500-3907-488f-b7d8-dace5b307bd8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c243c500-3907-488f-b7d8-dace5b307bd8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c243c500-3907-488f-b7d8-dace5b307bd8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e02e682b-3c8a-4675-b6fd-b85ca9d52341\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e02e682b-3c8a-4675-b6fd-b85ca9d52341')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e02e682b-3c8a-4675-b6fd-b85ca9d52341 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "Uhei0e71dSgp",
        "outputId": "b524b162-0288-47b1-d2b4-7d872afab396"
      },
      "id": "Uhei0e71dSgp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  category  \\\n",
              "1269  bhai is bar eid ap ka chera dekh kar ho gi .ka...  Positive   \n",
              "1828                     app ke intjar mein..luv u bhai  Positive   \n",
              "2530  salman bhai...suna hai ap ko kamar k takleef h...   Neutral   \n",
              "3231                                  ok salman bha!!!!   Neutral   \n",
              "1294                  zara pucho salman se k kitna raha   Neutral   \n",
              "\n",
              "      Capital_Words_Count  Extended_Words_Count  Exclamation_at_End  \\\n",
              "1269                    0                     2                   0   \n",
              "1828                    0                     1                   0   \n",
              "2530                    4                     4                   0   \n",
              "3231                    0                     0                   1   \n",
              "1294                    0                     0                   0   \n",
              "\n",
              "      Repeated_Punctuation_Count  Sentiment_Scores_positive  \\\n",
              "1269                           0                       0.25   \n",
              "1828                           1                       0.00   \n",
              "2530                           3                       0.00   \n",
              "3231                           1                       0.00   \n",
              "1294                           0                       0.00   \n",
              "\n",
              "      Sentiment_Scores_negetive  \n",
              "1269                      0.125  \n",
              "1828                      0.000  \n",
              "2530                      0.000  \n",
              "3231                      0.000  \n",
              "1294                      0.000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-594267f7-1159-4ce3-b2d4-997f9af9aca1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>Capital_Words_Count</th>\n",
              "      <th>Extended_Words_Count</th>\n",
              "      <th>Exclamation_at_End</th>\n",
              "      <th>Repeated_Punctuation_Count</th>\n",
              "      <th>Sentiment_Scores_positive</th>\n",
              "      <th>Sentiment_Scores_negetive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1269</th>\n",
              "      <td>bhai is bar eid ap ka chera dekh kar ho gi .ka...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1828</th>\n",
              "      <td>app ke intjar mein..luv u bhai</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2530</th>\n",
              "      <td>salman bhai...suna hai ap ko kamar k takleef h...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3231</th>\n",
              "      <td>ok salman bha!!!!</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>zara pucho salman se k kitna raha</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-594267f7-1159-4ce3-b2d4-997f9af9aca1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-594267f7-1159-4ce3-b2d4-997f9af9aca1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-594267f7-1159-4ce3-b2d4-997f9af9aca1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-299e3728-1bbc-4096-9642-516917c978bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-299e3728-1bbc-4096-9642-516917c978bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-299e3728-1bbc-4096-9642-516917c978bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7432989",
      "metadata": {
        "id": "f7432989",
        "outputId": "61149c67-a7ee-4a41-8174-fe541e30103f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Neutral', 1: 'Positive', 2: 'Negative'}\n"
          ]
        }
      ],
      "source": [
        "idx2label = {i:w for (w, i) in label2idx.items()}\n",
        "print(idx2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained SentencePiece Embeddings"
      ],
      "metadata": {
        "id": "nlCZsvIDb2_4"
      },
      "id": "nlCZsvIDb2_4"
    },
    {
      "cell_type": "code",
      "source": [
        "vocab,embeddings = [],[]\n",
        "with open('/content/drive/MyDrive/nlp_project/custom_embedding.txt','rt') as fi:\n",
        "    full_content = fi.read().strip().split('\\n')\n",
        "for i in range(len(full_content)):\n",
        "    i_word = full_content[i].split(' ')[0]\n",
        "    i_embeddings = [float(val) for val in full_content[i].split(' ')[1:]]\n",
        "    vocab.append(i_word)\n",
        "    embeddings.append(i_embeddings)"
      ],
      "metadata": {
        "id": "70ne4a-FHq11"
      },
      "execution_count": null,
      "outputs": [],
      "id": "70ne4a-FHq11"
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_npa = np.array(vocab)\n",
        "embs_npa = np.array(embeddings)"
      ],
      "metadata": {
        "id": "IznVCK83LQkw"
      },
      "execution_count": null,
      "outputs": [],
      "id": "IznVCK83LQkw"
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab_npa), print(vocab_npa[:10])"
      ],
      "metadata": {
        "id": "hb4b3HQkds9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "461b8324-2868-4f6c-e40d-94d8eac76300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>' '<s>' '</s>' 's' '▁the' '▁' '▁to' 'e' '▁i' '▁you']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, None)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "id": "hb4b3HQkds9h"
    },
    {
      "cell_type": "code",
      "source": [
        "embs_npa.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh7RR5a75cO7",
        "outputId": "0cc5fd68-d301-4a3b-a827-6786d3d90839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "id": "Zh7RR5a75cO7"
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_npa = np.insert(vocab_npa, 0, '<pad>')\n",
        "# vocab_npa = np.insert(vocab_npa, 1, '[UNK]')\n",
        "print(vocab_npa[:10])\n",
        "\n",
        "pad_emb_npa = np.zeros((1,embs_npa.shape[1]))   #embedding for '<pad>' token.\n",
        "# unk_emb_npa = np.mean(embs_npa,axis=0,keepdims=True)    #embedding for '<unk>' token.\n",
        "\n",
        "#insert embeddings for pad and unk tokens at top of embs_npa.\n",
        "# embs_npa = np.vstack((pad_emb_npa,unk_emb_npa,embs_npa))\n",
        "embs_npa = np.vstack((pad_emb_npa,embs_npa))\n",
        "print(embs_npa.shape)"
      ],
      "metadata": {
        "id": "51wUtjf7LYJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815c2915-f0ba-4e5a-87d2-5543cc879a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>' '<unk>' '<s>' '</s>' 's' '▁the' '▁' '▁to' 'e' '▁i']\n",
            "(7001, 128)\n"
          ]
        }
      ],
      "id": "51wUtjf7LYJx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Embeddings Using FastText"
      ],
      "metadata": {
        "id": "UuPCzC78kRm9"
      },
      "id": "UuPCzC78kRm9"
    },
    {
      "cell_type": "code",
      "source": [
        "df.text.to_csv(r'data.txt', header=None, index=None, sep=' ', mode='a')"
      ],
      "metadata": {
        "id": "77m71xdXYOE6"
      },
      "id": "77m71xdXYOE6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fastText_model = fasttext.train_unsupervised('data.txt', model='skipgram', dim=300, minn=2, maxn=10)"
      ],
      "metadata": {
        "id": "Q2gSk1zOWtIH"
      },
      "id": "Q2gSk1zOWtIH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fastText_model['the'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP4vSpfvWtEk",
        "outputId": "37a3c0de-e826-47fe-cae0-e0639e416310"
      },
      "id": "tP4vSpfvWtEk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fastText_model.get_input_matrix().shape"
      ],
      "metadata": {
        "id": "lC_LKv2lWr2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97afa595-2bef-4e68-cb75-e22fdbc4e1fe"
      },
      "id": "lC_LKv2lWr2x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2002009, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing for Simple BiLSTM\n",
        "def text_to_sequence(text, fastText_model, max_seq_len=40, embedding_size=300):\n",
        "    tokens = simple_preprocess(text)\n",
        "    vectors = []\n",
        "    for token in text:\n",
        "        if token in fastText_model:\n",
        "            vectors.append(fastText_model[token])\n",
        "        else:\n",
        "            vectors.append(np.zeros(embedding_size))\n",
        "\n",
        "    if len(vectors) < max_seq_len:\n",
        "        padding = [np.zeros(embedding_size)] * (max_seq_len - len(vectors))\n",
        "        vectors += padding\n",
        "    else:\n",
        "        vectors = vectors[:max_seq_len]\n",
        "\n",
        "    emb = np.array(vectors)\n",
        "    return emb\n",
        "\n",
        "def generate_subword_embeddings(df, fastText_model, max_seq_len=40):\n",
        "    embeddings = []\n",
        "\n",
        "    for text in df['text']:\n",
        "        emb = text_to_sequence(text, fastText_model, max_seq_len)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    return np.array(embeddings),np.array(df.drop(['text', 'category'],axis=1))"
      ],
      "metadata": {
        "id": "Bw05OR3eBx96"
      },
      "id": "Bw05OR3eBx96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idxLower = {\n",
        "    word: index\n",
        "    for index, word in enumerate(vocab_npa)\n",
        "}"
      ],
      "metadata": {
        "id": "54dQ-TU8kuxf"
      },
      "id": "54dQ-TU8kuxf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings, train_fn = generate_subword_embeddings(train_df, fastText_model)\n",
        "val_embeddings, val_fn = generate_subword_embeddings(val_df, fastText_model)\n",
        "test_embeddings, test_fn = generate_subword_embeddings(test_df, fastText_model)"
      ],
      "metadata": {
        "id": "3AKUNiClB6CT"
      },
      "id": "3AKUNiClB6CT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing for Modified Mukherjee\n",
        "def text_to_sequence(text, fastText_model, max_seq_len=40, embedding_size=300):\n",
        "    tokens = simple_preprocess(text)\n",
        "    vectors = []\n",
        "    # Fasttext\n",
        "    for token in text:\n",
        "        if token in fastText_model:\n",
        "            vectors.append(fastText_model[token])\n",
        "        else:\n",
        "            vectors.append(np.zeros(embedding_size))\n",
        "\n",
        "    if len(vectors) < max_seq_len:\n",
        "        padding = [np.zeros(embedding_size)] * (max_seq_len - len(vectors))\n",
        "        vectors += padding\n",
        "    else:\n",
        "        vectors = vectors[:max_seq_len]\n",
        "\n",
        "    emb = np.array(vectors)\n",
        "    # sentencepiece\n",
        "    seq=  [\n",
        "        word2idxLower.get(word, word2idxLower.get('<unk>'))\n",
        "        for word in text\n",
        "    ]\n",
        "    if len(seq) < max_seq_len:\n",
        "        padding = [0] * (max_seq_len - len(seq))\n",
        "        seq += padding\n",
        "    else:\n",
        "        seq = seq[:max_seq_len]\n",
        "    return emb, seq\n",
        "\n",
        "def generate_subword_embeddings(df, fastText_model, max_seq_len=40):\n",
        "    embeddings = []\n",
        "    embeddings_bng = []\n",
        "    for text in df['text']:\n",
        "        emb, emb_bng = text_to_sequence(text, fastText_model, max_seq_len)\n",
        "        embeddings.append(emb)\n",
        "        embeddings_bng.append(emb_bng)\n",
        "\n",
        "\n",
        "    return np.array(embeddings),np.array(embeddings_bng), np.array(df.drop(['text', 'category'],axis=1))"
      ],
      "metadata": {
        "id": "WV-Jhll7g9Hc"
      },
      "id": "WV-Jhll7g9Hc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cafe491",
      "metadata": {
        "id": "3cafe491"
      },
      "outputs": [],
      "source": [
        "train_embeddings,train_embeddings_bng, train_fn = generate_subword_embeddings(train_df, fastText_model)\n",
        "val_embeddings,val_embeddings_bng, val_fn = generate_subword_embeddings(val_df, fastText_model)\n",
        "test_embeddings ,test_embeddings_bng, test_fn = generate_subword_embeddings(test_df, fastText_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf42a3f",
      "metadata": {
        "id": "6bf42a3f"
      },
      "outputs": [],
      "source": [
        "train_embeddings = torch.Tensor(train_embeddings)\n",
        "train_embeddings_bng = torch.Tensor(train_embeddings_bng)\n",
        "train_fn = torch.Tensor(train_fn)\n",
        "train_labels = torch.Tensor(train_df['category'].values)\n",
        "\n",
        "val_embeddings = torch.Tensor(val_embeddings)\n",
        "val_embeddings_bng = torch.Tensor(val_embeddings_bng)\n",
        "val_fn = torch.Tensor(val_fn)\n",
        "val_labels = torch.Tensor(val_df['category'].values)\n",
        "\n",
        "test_embeddings = torch.Tensor(test_embeddings)\n",
        "test_embeddings_bng = torch.Tensor(test_embeddings_bng)\n",
        "test_fn = torch.Tensor(test_fn)\n",
        "test_labels = torch.Tensor(test_df['category'].values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d342c4b",
      "metadata": {
        "id": "0d342c4b"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "train_data = TensorDataset(train_embeddings, train_embeddings_bng , train_fn, train_labels)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_data = TensorDataset(val_embeddings, val_embeddings_bng , val_fn, val_labels)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_data = TensorDataset(test_embeddings, test_embeddings_bng , test_fn, test_labels)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def maori_train_with_early_stopping(model, train_loader=train_loader, val_loader=val_loader, num_epochs=50, patience=10):\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_f1 = 0\n",
        "    current_patience = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for inputs, inputs_fn, labels in train_loader:\n",
        "            inputs, inputs_fn, labels = inputs.to(device), inputs_fn.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            out = model(inputs, inputs_fn)\n",
        "            loss = criterion(out, labels.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_predictions = []\n",
        "        val_targets = []\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs,inputs_fn, labels in val_loader:\n",
        "                inputs, inputs_fn, labels = inputs.to(device), inputs_fn.to(device), labels.to(device)\n",
        "                out = model(inputs, inputs_fn)\n",
        "\n",
        "                loss = criterion(out, labels.long())\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(out, 1)\n",
        "\n",
        "                val_predictions.extend(predicted.cpu().long().numpy())\n",
        "                val_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "                # print(len(val_targets), val_targets[-10:])\n",
        "                # print(len(val_predictions), val_predictions[-10:])\n",
        "\n",
        "        # val_accuracy = accuracy_score(val_targets, val_predictions)\n",
        "        val_loss /= len(val_loader)\n",
        "        val_w_f1 = f1_score(val_targets, val_predictions, average='weighted')\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {mean_loss}, Validation Loss: {val_loss}, Validation F1: {val_w_f1}')\n",
        "\n",
        "        if val_w_f1 > best_val_f1:\n",
        "            best_val_f1 = val_w_f1\n",
        "            current_patience = 0\n",
        "            best_model = copy.deepcopy(model)\n",
        "        else:\n",
        "            current_patience += 1\n",
        "\n",
        "        # if current_patience >= patience:\n",
        "        #     print(f'Stopping after {epoch+1} epochs')\n",
        "        #     break\n",
        "\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "SO7rmLjMKZw9"
      },
      "id": "SO7rmLjMKZw9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maori_test_metrics(model, test_loader):\n",
        "    model.eval()\n",
        "    test_predictions = []\n",
        "    test_targets = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, inputs_fn, labels in test_loader:\n",
        "            inputs, inputs_fn, labels = inputs.to(device), inputs_fn.to(device), labels.to(device)\n",
        "            out = model(inputs, inputs_fn)\n",
        "\n",
        "            _, predicted = torch.max(out, 1)\n",
        "            test_predictions.extend(predicted.cpu().long().numpy())\n",
        "            test_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(len(test_targets), len(test_predictions))\n",
        "\n",
        "    test_acc = accuracy_score(test_targets, test_predictions)\n",
        "    test_w_f1 = f1_score(test_targets, test_predictions, average='weighted')\n",
        "    test_macro_f1 = f1_score(test_targets, test_predictions, average='macro')\n",
        "    class_report = classification_report(test_targets, test_predictions)\n",
        "\n",
        "    print('Accuracy:', test_acc)\n",
        "    print('F1-Weighted:', test_w_f1)\n",
        "    print('F1-Macro:', test_macro_f1)\n",
        "    print('Classification Report:', class_report, sep='\\n')"
      ],
      "metadata": {
        "id": "ElAJTEfnLfMq"
      },
      "id": "ElAJTEfnLfMq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3041c771",
      "metadata": {
        "id": "3041c771"
      },
      "outputs": [],
      "source": [
        "def train_with_early_stopping(model, train_loader=train_loader, val_loader=val_loader, num_epochs=50, patience=10):\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_f1 = 0\n",
        "    current_patience = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for inputs, inputs_bng, inputs_fn, labels in train_loader:\n",
        "            inputs,inputs_bng, inputs_fn, labels = inputs.to(device),inputs_bng.to(device), inputs_fn.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            out = model(inputs,inputs_bng, inputs_fn)\n",
        "            loss = criterion(out, labels.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_predictions = []\n",
        "        val_targets = []\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs,inputs_bng, inputs_fn, labels in val_loader:\n",
        "                inputs,inputs_bng, inputs_fn, labels = inputs.to(device),inputs_bng.to(device), inputs_fn.to(device), labels.to(device)\n",
        "                out = model(inputs,inputs_bng, inputs_fn)\n",
        "\n",
        "                loss = criterion(out, labels.long())\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(out, 1)\n",
        "\n",
        "                val_predictions.extend(predicted.cpu().long().numpy())\n",
        "                val_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "                # print(len(val_targets), val_targets[-10:])\n",
        "                # print(len(val_predictions), val_predictions[-10:])\n",
        "\n",
        "        # val_accuracy = accuracy_score(val_targets, val_predictions)\n",
        "        val_loss /= len(val_loader)\n",
        "        val_w_f1 = f1_score(val_targets, val_predictions, average='weighted')\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {mean_loss}, Validation Loss: {val_loss}, Validation F1: {val_w_f1}')\n",
        "\n",
        "        if val_w_f1 > best_val_f1:\n",
        "            best_val_f1 = val_w_f1\n",
        "            current_patience = 0\n",
        "            best_model = copy.deepcopy(model)\n",
        "        else:\n",
        "            current_patience += 1\n",
        "\n",
        "        if current_patience >= patience:\n",
        "            print(f'Stopping after {epoch+1} epochs')\n",
        "            break\n",
        "\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28101eae",
      "metadata": {
        "id": "28101eae"
      },
      "outputs": [],
      "source": [
        "def test_metrics(model, test_loader):\n",
        "    model.eval()\n",
        "    test_predictions = []\n",
        "    test_targets = []\n",
        "    with torch.no_grad():\n",
        "        for inputs,inputs_bng, inputs_fn, labels in test_loader:\n",
        "            inputs,inputs_bng, inputs_fn, labels = inputs.to(device),inputs_bng.to(device), inputs_fn.to(device), labels.to(device)\n",
        "            out = model(inputs,inputs_bng, inputs_fn)\n",
        "\n",
        "            _, predicted = torch.max(out, 1)\n",
        "            test_predictions.extend(predicted.cpu().long().numpy())\n",
        "            test_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(len(test_targets), len(test_predictions))\n",
        "\n",
        "    test_acc = accuracy_score(test_targets, test_predictions)\n",
        "    test_w_f1 = f1_score(test_targets, test_predictions, average='weighted')\n",
        "    test_macro_f1 = f1_score(test_targets, test_predictions, average='macro')\n",
        "    class_report = classification_report(test_targets, test_predictions)\n",
        "\n",
        "    print('Accuracy:', test_acc)\n",
        "    print('F1-Weighted:', test_w_f1)\n",
        "    print('F1-Macro:', test_macro_f1)\n",
        "    print('Classification Report:', class_report, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple BiLSTM Model"
      ],
      "metadata": {
        "id": "BaP8WTG4ZMcE"
      },
      "id": "BaP8WTG4ZMcE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ebe1d5b",
      "metadata": {
        "id": "4ebe1d5b",
        "outputId": "5d5048c2-ce32-4a06-ca81-47b090990375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maori(\n",
            "  (lstm): LSTM(300, 128, batch_first=True, bidirectional=True)\n",
            "  (drop): Dropout(p=0.0, inplace=False)\n",
            "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (linear2): Linear(in_features=128, out_features=3, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Maori(nn.Module): #Ignore\n",
        "    def __init__(self, input_size=300, hidden_size=128, out_size=3, dropout_prob=0.5):\n",
        "        super(Maori, self).__init__()\n",
        "        # self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embs_npa).float())\n",
        "        # self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embs_npa).float(), freeze=True)\n",
        "        self.lstm = nn.LSTM(input_size, 128, batch_first=True, bidirectional=True)\n",
        "        self.drop = nn.Dropout(dropout_prob)\n",
        "        self.linear1 = nn.Linear(2*128, 128)\n",
        "        self.linear2 = nn.Linear(128, out_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, fn):\n",
        "        out = self.drop(x)\n",
        "        out, _ = self.lstm(x)\n",
        "        # out = self.drop(out)\n",
        "\n",
        "\n",
        "        # out = torch.cat((out[:, -1, :], fn), dim=1)\n",
        "        # out = self.relu(self.linear1(out))\n",
        "        out = self.relu(self.linear1(out[:, -1, :]))\n",
        "        out = self.relu(self.linear2(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "model = Maori(out_size=len(idx2label), dropout_prob=0.)\n",
        "model = model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class_weights = [1.0,5.0,5.0]\n",
        "# criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adamax(model.parameters())"
      ],
      "metadata": {
        "id": "T4vm_obKY_RL"
      },
      "id": "T4vm_obKY_RL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maori_train_with_early_stopping(model, num_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKib6m0hLDmt",
        "outputId": "9307a29d-5055-4805-dd0c-2693506a7be8"
      },
      "id": "hKib6m0hLDmt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:19,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Loss: 1.0126256102865392, Validation Loss: 1.0252678394317627, Validation F1: 0.31738143956793474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:00<00:15,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/50], Train Loss: 0.9786363677545027, Validation Loss: 1.0160928606986999, Validation F1: 0.31738143956793474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:00<00:13,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/50], Train Loss: 0.9744742810726166, Validation Loss: 1.0016358733177184, Validation F1: 0.3749905650408345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:01<00:13,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/50], Train Loss: 0.9776825349439274, Validation Loss: 1.0101813793182373, Validation F1: 0.3166503564937788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:01<00:12,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/50], Train Loss: 0.9731361622160132, Validation Loss: 1.0047687411308288, Validation F1: 0.3166503564937788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:01<00:12,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/50], Train Loss: 0.9732407480478287, Validation Loss: 1.0023919105529786, Validation F1: 0.32190105434897837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:02<00:11,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/50], Train Loss: 0.9733887057412755, Validation Loss: 1.000680923461914, Validation F1: 0.32275048035998716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:02<00:11,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/50], Train Loss: 0.9739994948560541, Validation Loss: 1.0068877696990968, Validation F1: 0.3166503564937788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:02<00:11,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/50], Train Loss: 0.9715606624429877, Validation Loss: 1.0010486364364624, Validation F1: 0.3699819939895874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:02<00:10,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Train Loss: 0.9718392233956944, Validation Loss: 1.001455545425415, Validation F1: 0.3166503564937788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:03<00:10,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/50], Train Loss: 0.9706020883538506, Validation Loss: 1.0025289416313172, Validation F1: 0.39106425536977596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:03<00:10,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/50], Train Loss: 0.9721401130611246, Validation Loss: 0.9938232421875, Validation F1: 0.347845154702287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:03<00:09,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/50], Train Loss: 0.9735771024769003, Validation Loss: 0.9989508390426636, Validation F1: 0.3750181868443642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [00:03<00:09,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/50], Train Loss: 0.9698811024427414, Validation Loss: 0.9996514320373535, Validation F1: 0.34150157443896295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [00:04<00:09,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/50], Train Loss: 0.9696342470971021, Validation Loss: 1.0113938927650452, Validation F1: 0.3945110150353243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [00:04<00:08,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/50], Train Loss: 0.9700049039992419, Validation Loss: 1.0016149282455444, Validation F1: 0.3763401857003505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [00:04<00:08,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/50], Train Loss: 0.9672465988180854, Validation Loss: 0.9878897190093994, Validation F1: 0.4207573034395543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [00:04<00:08,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/50], Train Loss: 0.9639835154468362, Validation Loss: 0.9954240679740906, Validation F1: 0.36026213756972747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [00:05<00:08,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/50], Train Loss: 0.9628474847836928, Validation Loss: 1.0071916222572326, Validation F1: 0.41102763424130917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [00:05<00:07,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/50], Train Loss: 0.9577573144977743, Validation Loss: 0.9935874938964844, Validation F1: 0.44872865316630756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [00:05<00:07,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/50], Train Loss: 0.9673152796246789, Validation Loss: 1.0099802613258362, Validation F1: 0.40688653577551465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [00:05<00:07,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/50], Train Loss: 0.9646910564465956, Validation Loss: 1.0074869751930238, Validation F1: 0.4356161557961349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [00:06<00:07,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/50], Train Loss: 0.9678302976218137, Validation Loss: 1.0086477279663086, Validation F1: 0.3805383961391521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [00:06<00:06,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/50], Train Loss: 0.9662614681503989, Validation Loss: 1.0233513712882996, Validation F1: 0.3221140827186966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [00:06<00:06,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/50], Train Loss: 0.9677896784110502, Validation Loss: 1.014790916442871, Validation F1: 0.3285320808298487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [00:07<00:06,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/50], Train Loss: 0.9639377729459242, Validation Loss: 1.0048292398452758, Validation F1: 0.38060893701883497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [00:07<00:06,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/50], Train Loss: 0.9626413394104351, Validation Loss: 0.9925892114639282, Validation F1: 0.34931019101436644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [00:07<00:05,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/50], Train Loss: 0.961876320567998, Validation Loss: 0.997131073474884, Validation F1: 0.37795832615900443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [00:07<00:05,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/50], Train Loss: 0.9544669796120037, Validation Loss: 0.9929499864578247, Validation F1: 0.45075142011721986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [00:08<00:05,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/50], Train Loss: 0.9536270932717756, Validation Loss: 0.9981137633323669, Validation F1: 0.4666473332385918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [00:08<00:04,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/50], Train Loss: 0.954218169504946, Validation Loss: 0.9914943933486938, Validation F1: 0.4605807159859716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [00:08<00:04,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/50], Train Loss: 0.9558171887289394, Validation Loss: 0.9927423000335693, Validation F1: 0.4753801200233147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [00:08<00:04,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/50], Train Loss: 0.9570438712835312, Validation Loss: 0.9842432618141175, Validation F1: 0.3983243444658236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [00:09<00:04,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/50], Train Loss: 0.9556299082257531, Validation Loss: 0.9812075734138489, Validation F1: 0.4710940962367163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [00:09<00:04,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/50], Train Loss: 0.9536373940381137, Validation Loss: 0.9846975445747376, Validation F1: 0.4740696750215897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [00:09<00:04,  3.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/50], Train Loss: 0.9515974169427698, Validation Loss: 0.9855929255485535, Validation F1: 0.46185789940660504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [00:10<00:03,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/50], Train Loss: 0.9496225294741717, Validation Loss: 0.9877636790275574, Validation F1: 0.4657707110965862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [00:10<00:03,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/50], Train Loss: 0.9557356157086112, Validation Loss: 1.0081122756004333, Validation F1: 0.3778749915860219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [00:10<00:03,  3.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/50], Train Loss: 0.9528463252566077, Validation Loss: 0.9891589164733887, Validation F1: 0.44674084030483613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [00:11<00:03,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/50], Train Loss: 0.9574366848577153, Validation Loss: 0.9887640595436096, Validation F1: 0.4459346597368378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [00:11<00:02,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/50], Train Loss: 0.9506409005685286, Validation Loss: 0.9982756972312927, Validation F1: 0.4460961790998067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [00:11<00:02,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/50], Train Loss: 0.9485839212482626, Validation Loss: 1.0007559061050415, Validation F1: 0.45107273603178943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [00:11<00:02,  3.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/50], Train Loss: 0.9562153057618574, Validation Loss: 0.985238254070282, Validation F1: 0.4693939376508733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [00:12<00:01,  3.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/50], Train Loss: 0.9493818797848441, Validation Loss: 0.9853189587593079, Validation F1: 0.4452953423054685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [00:12<00:01,  3.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/50], Train Loss: 0.9427786699750207, Validation Loss: 0.9890804767608643, Validation F1: 0.45617834571064203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [00:12<00:01,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/50], Train Loss: 0.9448314349759709, Validation Loss: 0.9862893700599671, Validation F1: 0.4592923609352518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [00:13<00:00,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/50], Train Loss: 0.9503281604159962, Validation Loss: 0.9890114426612854, Validation F1: 0.4633920981631371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [00:13<00:00,  3.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/50], Train Loss: 0.945082122629339, Validation Loss: 0.9861586093902588, Validation F1: 0.4707253641006241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [00:13<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/50], Train Loss: 0.9420308077877219, Validation Loss: 0.9962305307388306, Validation F1: 0.4715268208033481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:14<00:00,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/50], Train Loss: 0.9432235712354834, Validation Loss: 0.9898252367973328, Validation F1: 0.44665764088678284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Maori(\n",
              "  (lstm): LSTM(300, 128, batch_first=True, bidirectional=True)\n",
              "  (drop): Dropout(p=0.0, inplace=False)\n",
              "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maori_test_metrics(model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3zalqCHLu8n",
        "outputId": "48416915-68d7-4a3f-d668-196190cb8539"
      },
      "id": "t3zalqCHLu8n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311 311\n",
            "Accuracy: 0.5080385852090032\n",
            "F1-Weighted: 0.44665764088678284\n",
            "F1-Macro: 0.34561403508771926\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.52      0.79      0.63       151\n",
            "         1.0       0.48      0.36      0.41       108\n",
            "         2.0       0.00      0.00      0.00        52\n",
            "\n",
            "    accuracy                           0.51       311\n",
            "   macro avg       0.33      0.38      0.35       311\n",
            "weighted avg       0.42      0.51      0.45       311\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maori_test_metrics(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GPBtm93Lz9b",
        "outputId": "b105c920-d4d0-4c68-9607-7a73c1fae39d"
      },
      "id": "9GPBtm93Lz9b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "776 776\n",
            "Accuracy: 0.5154639175257731\n",
            "F1-Weighted: 0.46532242121602624\n",
            "F1-Macro: 0.35014204545454547\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.74      0.64       395\n",
            "         1.0       0.43      0.40      0.41       265\n",
            "         2.0       0.00      0.00      0.00       116\n",
            "\n",
            "    accuracy                           0.52       776\n",
            "   macro avg       0.33      0.38      0.35       776\n",
            "weighted avg       0.43      0.52      0.47       776\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modified Mukherjee Model\n",
        "SentencePiece+FastText Embeddings with Attention and Feature Network"
      ],
      "metadata": {
        "id": "KB5I3ueEZSAJ"
      },
      "id": "KB5I3ueEZSAJ"
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.query = nn.Linear(input_dim, input_dim)\n",
        "        self.key = nn.Linear(input_dim, input_dim)\n",
        "        self.value = nn.Linear(input_dim, input_dim)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        queries = self.query(x)\n",
        "        keys = self.key(x)\n",
        "        values = self.value(x)\n",
        "        scores = torch.bmm(queries, keys.transpose(1, 2)) / (self.input_dim ** 0.5)\n",
        "        attention = self.softmax(scores)\n",
        "        weighted = torch.bmm(attention, values)\n",
        "        return weighted\n"
      ],
      "metadata": {
        "id": "h-13KjLe7ybz"
      },
      "id": "h-13KjLe7ybz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MukherjeeV3(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MukherjeeV3, self).__init__()\n",
        "\n",
        "        # Word Embeddings\n",
        "        self.lstm_word = nn.LSTM(config['word_input_size'], config['lstm_word_hidden'], num_layers=2, batch_first=True, bidirectional=True)\n",
        "        # self.dropout_word = nn.Dropout(config[\"drop_word\"])\n",
        "        self.attention_word = SelfAttention(config['lstm_word_hidden']*2)\n",
        "        # self.multihead_attn_word = nn.MultiheadAttention(config['lstm_word_hidden']*2, config['num_heads'])\n",
        "\n",
        "        # Char Embeddings\n",
        "        # self.lstm_char = nn.LSTM(config['input_size'], config['lstm_char_hidden'], batch_first=True, bidirectional=True)\n",
        "        # self.dropout_char = nn.Dropout(config[\"drop_char\"])\n",
        "\n",
        "        #Bangla Embeddings\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embs_npa).float(), freeze=True)\n",
        "        self.lstm = nn.LSTM(input_size = config['subword_input_size'], hidden_size = config['lstm_subword_hidden'], num_layers=4, bidirectional=True, batch_first=True)\n",
        "        # self.linear = nn.Linear(config['hidden_dim'] * 2,  config['num_heads'])\n",
        "        # self.dropout = nn.Dropout(config['drop_char'])\n",
        "        self.attention_subword = SelfAttention(config['lstm_subword_hidden']*2)\n",
        "        # self.multihead_attn_subword = nn.MultiheadAttention(config['hidden_dim']*2, config['num_heads'])\n",
        "\n",
        "        # Dense Layers\n",
        "        self.attention_both = SelfAttention(config['lstm_word_hidden']*2+config['lstm_subword_hidden']*2)\n",
        "        # self.multihead_attn_both = nn.MultiheadAttention(config['lstm_word_hidden']*2+config['hidden_dim']*2, config['num_heads'])\n",
        "\n",
        "        # self.dropout_fc1 = nn.Dropout(config[\"drop_fc\"])\n",
        "        # self.dropout_fc2 = nn.Dropout(config[\"drop_fc\"])\n",
        "        self.fc1 = nn.Linear(config['fc1_dim'], config['fc2_dim'])\n",
        "        self.fc2 = nn.Linear(config['fc2_dim'], config['fc3_dim'])\n",
        "        self.fc3 = nn.Linear(config['fc3_dim'], config['n_classes'])\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, x_bng, fn):\n",
        "        # Word Embeddings\n",
        "        out, (hidden,_) = self.lstm_word(x)\n",
        "        # out = self.dropout_word(out)\n",
        "        out_word = self.attention_word(out)\n",
        "        # out_word, _ = self.multihead_attn_word(out, out, out)\n",
        "\n",
        "        # Char Embeddings\n",
        "        # out, (hidden,_) = self.lstm_char(x)\n",
        "        # out_char = self.dropout_char(out)\n",
        "        out_subword = self.embedding(x_bng.long())\n",
        "        # print(x[0])\n",
        "        # print(embedded[0])\n",
        "        # print(embedded.shape)\n",
        "        out_subword, (hidden, _) = self.lstm(out_subword)\n",
        "        # embedded = self.dropout(embedded)\n",
        "        out_subword = self.attention_subword(out_subword)\n",
        "        # out, _ = self.multihead_attn_subword(embedded, embedded, embedded)\n",
        "        # outputs = self.linear(outputs)\n",
        "        # embedded =  outputs.transpose(1, 2)\n",
        "\n",
        "        # print(x[0])\n",
        "        # print(embedded[0])\n",
        "\n",
        "\n",
        "\n",
        "        # Concatenate Word and Char Embeddings\n",
        "        # print(out_word.shape)\n",
        "        # print(embedded.shape)\n",
        "        out = torch.cat((out_word, out_subword), dim=2)\n",
        "        # print(out.shape)\n",
        "        # print(out[:, -1, :].shape)\n",
        "        # expected_input_size = config['lstm_word_hidden']*2 + config['hidden_dim']*2\n",
        "        # print(f\"Expected input size of fully connected layer: {expected_input_size}\")\n",
        "        # out = out_word\n",
        "\n",
        "        # Attention\n",
        "        out = self.attention_both(out)\n",
        "        # out = self.multihead_attn_both(out,out,out)\n",
        "        # print(out.shape)\n",
        "        # print(out[:, -1, :].shape)\n",
        "        # print(fn.shape)\n",
        "        # out = torch.cat((out[:, -1, :], fn), dim=1)\n",
        "        # print(out.shape)\n",
        "        # x = torch.cat((x, any_caps.unsqueeze(2)), dim=2)\n",
        "        # Dense Layers\n",
        "        # out = self.relu(self.fc1(out))\n",
        "        out = self.relu(self.fc1(out[:, -1, :]))\n",
        "        # out = self.dropout_fc1(out)\n",
        "        out = self.relu(self.fc2(out))\n",
        "        # out = self.dropout_fc2(out)\n",
        "        out = self.relu(self.fc3(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "Uid3HLQFl6cD"
      },
      "id": "Uid3HLQFl6cD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config={'word_input_size':300,\n",
        "        'subword_input_size':128,\n",
        "        'lstm_word_hidden':300,\n",
        "        'lstm_subword_hidden':128,\n",
        "        # 'lstm_char_hidden':128,\n",
        "        'fc1_dim':300*2+128*2,\n",
        "        'fc2_dim':512,\n",
        "        'fc3_dim':128,\n",
        "        'n_classes':len(idx2label),\n",
        "        'drop_subword':0.2,\n",
        "        'drop_word':0.4,\n",
        "        'drop_fc':0.4,\n",
        "        # 'num_heads':8,\n",
        "        # 'embedding_dim' :128,\n",
        "        # 'hidden_dim' : 256,\n",
        "        }\n",
        "\n",
        "model = MukherjeeV3(config)\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "073Z343hAgIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f98eec8-ed76-4245-d247-e510d1c50fa4"
      },
      "id": "073Z343hAgIj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MukherjeeV1(\n",
            "  (lstm_word): LSTM(300, 300, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (attention_word): SelfAttention(\n",
            "    (query): Linear(in_features=600, out_features=600, bias=True)\n",
            "    (key): Linear(in_features=600, out_features=600, bias=True)\n",
            "    (value): Linear(in_features=600, out_features=600, bias=True)\n",
            "    (softmax): Softmax(dim=2)\n",
            "  )\n",
            "  (embedding): Embedding(7001, 128)\n",
            "  (lstm): LSTM(128, 128, num_layers=4, batch_first=True, bidirectional=True)\n",
            "  (attention_subword): SelfAttention(\n",
            "    (query): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (key): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (value): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (softmax): Softmax(dim=2)\n",
            "  )\n",
            "  (attention_both): SelfAttention(\n",
            "    (query): Linear(in_features=856, out_features=856, bias=True)\n",
            "    (key): Linear(in_features=856, out_features=856, bias=True)\n",
            "    (value): Linear(in_features=856, out_features=856, bias=True)\n",
            "    (softmax): Softmax(dim=2)\n",
            "  )\n",
            "  (fc1): Linear(in_features=856, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a654fd",
      "metadata": {
        "id": "77a654fd"
      },
      "outputs": [],
      "source": [
        "# class_weights = [1.0,5.0,5.0]\n",
        "# criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adamax(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f36920d",
      "metadata": {
        "id": "3f36920d",
        "outputId": "28140ee9-5bbd-444d-bdd6-87e27586f69c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:02<02:11,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Loss: 0.9999884556640278, Validation Loss: 1.0290299892425536, Validation F1: 0.31738143956793474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/50], Train Loss: 0.9449486637657339, Validation Loss: 0.9782434940338135, Validation F1: 0.37363538101682436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:07<02:02,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/50], Train Loss: 0.9239118817177686, Validation Loss: 0.9501007437705994, Validation F1: 0.48078770046904756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:10<01:59,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/50], Train Loss: 0.8776216615330089, Validation Loss: 0.9570084333419799, Validation F1: 0.5539961450277513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:12<01:56,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/50], Train Loss: 0.8465387401255694, Validation Loss: 0.8901437163352967, Validation F1: 0.5624225451607793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:15<01:53,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/50], Train Loss: 0.7717975852164355, Validation Loss: 0.8877434015274048, Validation F1: 0.5588425474368568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:18<01:51,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/50], Train Loss: 0.7032640386711467, Validation Loss: 0.8528868913650512, Validation F1: 0.6387327738313675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:20<01:48,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/50], Train Loss: 0.6447205042297189, Validation Loss: 0.9190383791923523, Validation F1: 0.6319297165401017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:23<01:46,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/50], Train Loss: 0.5805686834183607, Validation Loss: 0.885077440738678, Validation F1: 0.6272926352357947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:25<01:43,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Train Loss: 0.5118553597818721, Validation Loss: 1.02064688205719, Validation F1: 0.6341473801563923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:28<01:41,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/50], Train Loss: 0.4804725179618055, Validation Loss: 1.0500311970710754, Validation F1: 0.6002921457207877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:31<01:38,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/50], Train Loss: 0.4544908153739842, Validation Loss: 1.1345779657363892, Validation F1: 0.6585950284457913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:33<01:36,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/50], Train Loss: 0.4011682265184142, Validation Loss: 1.058588683605194, Validation F1: 0.6408190283328832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [00:36<01:34,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/50], Train Loss: 0.35496391220526263, Validation Loss: 1.182034397125244, Validation F1: 0.6278107026045642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [00:39<01:31,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/50], Train Loss: 0.3192114183171229, Validation Loss: 1.3921323776245118, Validation F1: 0.6476382484240798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [00:41<01:29,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/50], Train Loss: 0.2626191469078714, Validation Loss: 1.5629070043563842, Validation F1: 0.6165143677795711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [00:44<01:27,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/50], Train Loss: 0.2213521601462906, Validation Loss: 1.8115647315979004, Validation F1: 0.6363615136904771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [00:47<01:24,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/50], Train Loss: 0.20225927555425602, Validation Loss: 1.7080495595932006, Validation F1: 0.6117642092658976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [00:49<01:22,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/50], Train Loss: 0.17939212207089772, Validation Loss: 1.8048419237136841, Validation F1: 0.6248582265042812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [00:52<01:20,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/50], Train Loss: 0.14913088345730846, Validation Loss: 1.8600791215896606, Validation F1: 0.6331871032236824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [00:55<01:18,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/50], Train Loss: 0.1583293251354586, Validation Loss: 2.1493008136749268, Validation F1: 0.622958749003765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [00:57<01:20,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/50], Train Loss: 0.13371431996876543, Validation Loss: 1.9396701335906983, Validation F1: 0.6497668745956018\n",
            "Stopping after 22 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "best_model = train_with_early_stopping(model, num_epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d857bc",
      "metadata": {
        "id": "68d857bc",
        "outputId": "68e6b2fe-7a2c-49bf-a30a-1e879d39620c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:879: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
            "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "776 776\n",
            "Accuracy: 0.6108247422680413\n",
            "F1-Weighted: 0.6091328774086275\n",
            "F1-Macro: 0.5667373848718545\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.66      0.67       395\n",
            "         1.0       0.55      0.64      0.59       265\n",
            "         2.0       0.50      0.39      0.44       116\n",
            "\n",
            "    accuracy                           0.61       776\n",
            "   macro avg       0.58      0.56      0.57       776\n",
            "weighted avg       0.61      0.61      0.61       776\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_metrics(best_model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics(best_model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARsPGoxQGOmx",
        "outputId": "021a814d-f19f-410f-ddf1-41216bebcf69"
      },
      "id": "ARsPGoxQGOmx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "388 388\n",
            "Accuracy: 0.6262886597938144\n",
            "F1-Weighted: 0.5786135747404311\n",
            "F1-Macro: 0.44540006863599163\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.75      0.72       198\n",
            "         1.0       0.55      0.71      0.62       133\n",
            "         2.0       0.00      0.00      0.00        57\n",
            "\n",
            "    accuracy                           0.63       388\n",
            "   macro avg       0.41      0.49      0.45       388\n",
            "weighted avg       0.54      0.63      0.58       388\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:879: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
            "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics(best_model, train_loader)"
      ],
      "metadata": {
        "id": "KXMJGUb39saR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8ae84b-95d1-44a7-f6c1-2a20575fb5e2"
      },
      "id": "KXMJGUb39saR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:879: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
            "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2715 2715\n",
            "Accuracy: 0.7653775322283609\n",
            "F1-Weighted: 0.7116332715285199\n",
            "F1-Macro: 0.5390638523981881\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.92      0.86      1457\n",
            "         1.0       0.71      0.83      0.76       900\n",
            "         2.0       0.00      0.00      0.00       358\n",
            "\n",
            "    accuracy                           0.77      2715\n",
            "   macro avg       0.50      0.58      0.54      2715\n",
            "weighted avg       0.66      0.77      0.71      2715\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(best_model.state_dict(), '/content/drive/MyDrive/nlp_project/MukherjeeV2SpellCheck.pt')"
      ],
      "metadata": {
        "id": "FAmIfvdg9sXH"
      },
      "id": "FAmIfvdg9sXH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}